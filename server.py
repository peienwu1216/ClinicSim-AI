import os
import json
import random
import re
from flask import Flask, request, jsonify
from dotenv import load_dotenv

# å°å…¥æˆ‘å€‘æ–°å»ºçš„ RAG ç³»çµ±
from rag_handler import rag_system

# --- è‡ªå‹•ç’°å¢ƒåµæ¸¬èˆ‡è¨­å®š ---
load_dotenv() # å¾ .env æª”æ¡ˆè¼‰å…¥ç’°å¢ƒè®Šæ•¸

# åŸ·è¡Œè·¯å¾‘æ——æ¨™
PATH_A_DEMO = False    # AMD AI PC (Lemonade)
PATH_B_DEVELOPMENT = False # Mac/Windows (Ollama)

# åµæ¸¬è·¯å¾‘ Aï¼šå„ªå…ˆåµæ¸¬ Lemonade Server
try:
    # é€™è£¡å‡è¨­ lemonade server æœƒé€éæŸç¨®æ–¹å¼ expose å‡½å¼
    # ç”±æ–¼æˆ‘å€‘æ²’æœ‰ lemonade çš„å…·é«” APIï¼Œæˆ‘å€‘å°‡æ¨¡æ“¬ä¸€å€‹ expose è£é£¾å™¨
    # åœ¨çœŸå¯¦çš„ lemonade ç’°å¢ƒä¸­ï¼Œä½ å¯èƒ½éœ€è¦å¾ lemonade å°å…¥ expose
    from lemonade import expose
    PATH_A_DEMO = True
    print("âœ… åµæ¸¬åˆ° Lemonade ç’°å¢ƒ -> å•Ÿç”¨ã€è·¯ç·š A: Demo æ¨¡å¼ã€‘")
except (ImportError, ModuleNotFoundError):
    # å»ºç«‹ä¸€å€‹å‡çš„ expose è£é£¾å™¨ï¼Œè®“ç¨‹å¼ç¢¼åœ¨é–‹ç™¼æ¨¡å¼ä¸‹ä¹Ÿèƒ½é‹è¡Œ
    def expose(func):
        return func
        
    # åµæ¸¬è·¯å¾‘ Bï¼šè‹¥ç„¡ Lemonadeï¼Œå‰‡åµæ¸¬ Ollama è¨­å®š
    try:
        import ollama
        PATH_B_DEVELOPMENT = True
        OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434")
        OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3:8b")
        OLLAMA_CLIENT = ollama.Client(host=OLLAMA_HOST)
        print("âœ… åµæ¸¬åˆ° Ollama è¨­å®š -> å•Ÿç”¨ã€è·¯ç·š B: é–‹ç™¼æ¨¡å¼ã€‘")
        print(f"   ä½¿ç”¨æ¨¡å‹: {OLLAMA_MODEL}")
    except ImportError:
        print("âŒ éŒ¯èª¤ï¼šç¼ºå°‘ `ollama` å¥—ä»¶ã€‚è«‹åŸ·è¡Œ `pip install ollama`ã€‚")
    except Exception as e:
        print(f"ğŸŸ¡ è­¦å‘Šï¼šOllama é€£æ¥å¤±æ•—: {e}")
        print("ğŸŸ¡ å¾Œç«¯å°‡ä»¥ç„¡ AI åŠŸèƒ½çš„ç‹€æ…‹é‹è¡Œã€‚")

# --- Flask App åˆå§‹åŒ– ---
# åœ¨å…©ç¨®è·¯å¾‘ä¸‹æˆ‘å€‘éƒ½éœ€è¦ Flask app
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False

# --- è¼”åŠ©å‡½å¼ ---
def load_case_data(case_id: str) -> dict:
    """æ ¹æ“š case_id è¼‰å…¥å°æ‡‰çš„æ•™æ¡ˆ JSON æª”æ¡ˆ"""
    try:
        with open(f"cases/{case_id}.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return None

# --- æ ¸å¿ƒ AI æœå‹™å‡½å¼ (é›™è·¯å¾‘å¯¦ä½œ) ---
@expose
def ask_patient(history: list, case_id: str) -> str:
    """æ ¹æ“šå°è©±æ­·å²ç”Ÿæˆ AI ç—…äººçš„å›æ‡‰"""
    case_data = load_case_data(case_id)
    if not case_data:
        return "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„æ¡ˆä¾‹æª”æ¡ˆã€‚"

    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½æ¨¡æ“¬ç—…äººï¼ˆæ¨™æº–åŒ–ç—…äººï¼‰ã€‚ä½ çš„æ‰€æœ‰è¼¸å‡ºå¿…é ˆä½¿ç”¨ã€ç¹é«”ä¸­æ–‡ã€ã€‚
    ã€è§’è‰²è¨­å®šèˆ‡å›æ‡‰è¦å‰‡ã€‘
    1. åƒ…å›ç­”å­¸ç”Ÿï¼ˆuserï¼‰ç›´æ¥è©¢å•çš„å…§å®¹ï¼Œä¸ä¸»å‹•é€éœ²æœªè¢«è©¢å•çš„è³‡è¨Šã€‚
    2. å›è¦†æ ¼å¼éœ€ç‚ºã€Œ[å‹•ä½œ/æƒ…ç·’] å°è©±å…§å®¹ã€ã€‚
    3. åš´æ ¼ä¾æ“šä¸‹æ–¹å€‹æ¡ˆè³‡æ–™ä½œç­”ã€‚
    ã€å€‹æ¡ˆè¡Œç‚ºè¦ç¯„ã€‘: {json.dumps(case_data.get("ai_instructions", {}), ensure_ascii=False)}
    ã€å€‹æ¡ˆè³‡æ–™ã€‘: {json.dumps(case_data.get("patient_story_data", {}), ensure_ascii=False)}
    è«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šå’Œå°è©±æ­·å²ï¼Œä½œç‚ºç—…äººï¼Œä»¥ã€Œç¹é«”ä¸­æ–‡ã€å›è¦†ä¸‹ä¸€å¥è©±ã€‚åˆ‡è¨˜çµ•å°è¦å‰‡ï¼šæ‰€æœ‰è¼¸å‡ºæ–‡å­—éƒ½è¦æ˜¯ç¹é«”ä¸­æ–‡ï¼ï¼
    """
    messages = [{"role": "system", "content": system_prompt}] + history

    # --- è·¯ç·š A: Demo (Lemonade) ---
    if PATH_A_DEMO:
        print("[Lemonade] æ­£åœ¨å‘¼å«èªè¨€æ¨¡å‹...")
        # é€™è£¡æ˜¯ä½ å¯¦éš›å‘¼å« lemonade LLM çš„åœ°æ–¹
        # response = lemonade.llm.chat(model="Qwen3-1.7B-GGUF", messages=messages)
        # return response.choices[0].message.content
        return "[From Lemonade] [è¡¨æƒ…ç—›è‹¦] é†«ç”Ÿï¼Œæˆ‘èƒ¸å£çœŸçš„å¾ˆç—›..."

    # --- è·¯ç·š B: é–‹ç™¼ (Ollama) ---
    elif PATH_B_DEVELOPMENT:
        model_name = os.getenv("OLLAMA_MODEL", "llama3:8b")
        print(f"[Ollama] æ­£åœ¨å‘¼å«æ¨¡å‹: {model_name}...")
        response = OLLAMA_CLIENT.chat(
            model=model_name,
            messages=messages
        )
        return response['message']['content']
        
    # --- å‚™ç”¨ï¼šç„¡ AI ç’°å¢ƒ ---
    else:
        return "[ç„¡ AI] é€™æ˜¯ä¸€å€‹å‚™ç”¨å›æ‡‰ï¼Œè«‹æª¢æŸ¥ä½ çš„ Lemonade æˆ– .env è¨­å®šã€‚"

@expose
def get_feedback_report(full_conversation: list, case_id: str) -> dict:
    """
    ç”Ÿæˆè¨ºå¾Œåˆ†æå ±å‘Šã€å·²æ•´åˆ RAG åŠŸèƒ½ã€‘ã€‚
    """
    print("\n[å ±å‘Šç”Ÿæˆ] é–‹å§‹ç”Ÿæˆåˆ†æå ±å‘Š...")
    
    case_data = load_case_data(case_id)
    if not case_data:
        return {"error": f"Case '{case_id}' not found"}

    # è®€å–å›é¥‹ç³»çµ±é…ç½®
    feedback_system = case_data.get("feedback_system", {})
    checklist = feedback_system.get("checklist", [])
    critical_actions = feedback_system.get("critical_actions", [])
    
    # å°‡å°è©±è½‰æ›ç‚ºæ–‡å­—æ ¼å¼
    conversation_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in full_conversation])
    
    # å°‡æª¢æŸ¥æ¸…å–®è½‰æ›ç‚ºæ–‡å­—æ ¼å¼
    checklist_text = "\n".join([f"- {item['point']} (é¡åˆ¥: {item['category']})" for item in checklist])
    
    # å°‡é—œéµè¡Œå‹•è½‰æ›ç‚ºæ–‡å­—æ ¼å¼
    critical_actions_text = "\n".join([f"- {action}" for action in critical_actions])

    # 1. æ¨¡æ“¬è©•åˆ†ï¼Œä¸¦æ‰¾å‡ºéœ€è¦ RAG æä¾›å»ºè­°çš„å¼±é»
    # åœ¨çœŸå¯¦æƒ…å¢ƒä¸­ï¼Œé€™æœƒæ˜¯ä½ çš„è©•åˆ†å¼•æ“çš„è¼¸å‡º
    student_weakness_query = "ç‚ºä»€éº¼åœ¨æ€¥æ€§èƒ¸ç—›çš„æ¡ˆä¾‹ä¸­ï¼ŒECG å¿ƒé›»åœ–æ˜¯ç¬¬ä¸€å„ªå…ˆçš„æª¢æŸ¥ï¼Ÿ"
    
    # 2. ä½¿ç”¨ RAG ç³»çµ±æœå°‹ç›¸é—œçŸ¥è­˜
    # é€™ä¸€å‘¼å«æ˜¯ç¨ç«‹æ–¼èªè¨€æ¨¡å‹çš„
    rag_context = rag_system.search(student_weakness_query)
    
    # 3. å°‡ RAG çµæœæ³¨å…¥åˆ° Prompt ä¸­ï¼Œäº¤çµ¦èªè¨€æ¨¡å‹é€²è¡Œç¸½çµ
    prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ OSCE è‡¨åºŠæ•™å¸«ã€‚è«‹æ ¹æ“šä»¥ä¸‹èƒŒæ™¯è³‡æ–™å’Œå­¸ç”Ÿçš„å°è©±ç´€éŒ„ï¼Œç”Ÿæˆä¸€ä»½å°ˆæ¥­çš„è¨ºå¾Œåˆ†æå ±å‘Šã€‚

    ### å­¸ç”Ÿè¡¨ç¾
    {conversation_text}

    ### è©•ä¼°æ¸…å–®
    {checklist_text}

    ### é—œéµè¡Œå‹•
    {critical_actions_text}

    ### ç›¸é—œè‡¨åºŠæŒ‡å¼• (ç”± RAG ç³»çµ±æä¾›)
    {rag_context}

    ### ä½ çš„ä»»å‹™
    è«‹åŸºæ–¼ä»¥ä¸Šæ‰€æœ‰è³‡è¨Šï¼Œæ’°å¯«ä¸€ä»½åŒ…å«ä»¥ä¸‹å¹¾é»çš„åˆ†æå ±å‘Šï¼š
    1.  **é—œéµéŒ¯å¤±é»**: å­¸ç”Ÿåœ¨å•è¨ºæˆ–æ±ºç­–ä¸­å¯èƒ½å¿½ç•¥çš„é‡é»ã€‚
    2.  **å»ºè¨­æ€§å»ºè­°**: æ ¹æ“š RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•ï¼Œçµ¦å‡ºå…·é«”ã€æœ‰ä¾æ“šçš„æ”¹é€²å»ºè­°ã€‚
    3.  **è©•ä¼°ç­‰ç´š**: æ¯é …çµ¦å‡ºç­‰ç´šï¼šâœ…(å®Œæ•´)ã€âš ï¸(éƒ¨åˆ†)ã€âŒ(æœªå•)
    4.  **å…·é«”ä¾æ“š**: å¼•ç”¨å­¸ç”Ÿå…·é«”æå•ä½œç‚ºè©•ä¼°ä¾æ“š

    è¼¸å‡ºæ ¼å¼ï¼š
    ### è¨ºå¾Œåˆ†æå ±å‘Š
    - [ç­‰ç´š] [é …ç›®]ï¼šå…·é«”ä¾æ“š
    ### ç¸½çµèˆ‡å»ºè­°
    æ”¹é€²å»ºè­°
    """

    messages = [{"role": "system", "content": prompt}]

    # --- è·¯ç·š A: Demo (Lemonade) ---
    if PATH_A_DEMO:
        print("[Lemonade] æ­£åœ¨å‘¼å«èªè¨€æ¨¡å‹ç”Ÿæˆåˆ†æå ±å‘Š...")
        # é€™è£¡æ˜¯ä½ å¯¦éš›å‘¼å« lemonade LLM çš„åœ°æ–¹
        # response = lemonade.llm.chat(model="Qwen3-1.7B-GGUF", messages=messages)
        # return {"report_text": response.choices[0].message.content}
        return {"report_text": f"[From Lemonade] å ±å‘Šåˆ†æï¼šå­¸ç”Ÿæ‡‰å„ªå…ˆè€ƒæ…® ECGã€‚\n\nè­‰æ“šï¼š{rag_context}"}

    # --- è·¯ç·š B: é–‹ç™¼ (Ollama) ---
    elif PATH_B_DEVELOPMENT:
        print(f"[Ollama] æ­£åœ¨ç”Ÿæˆå ±å‘Š...")
        try:
            response = OLLAMA_CLIENT.chat(
                model=os.getenv("OLLAMA_MODEL"),
                messages=messages
            )
            report_text = response['message']['content']
        except Exception as e:
            print(f"[Ollama] ç”Ÿæˆå ±å‘Šå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ: {e}")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å¢å¼·ç‰ˆåˆ†æ
            user_messages = [msg['content'] for msg in full_conversation if msg['role'] == 'user']
            conversation_analysis = analyze_conversation_enhanced(user_messages, checklist, critical_actions)
            report_text = f"{conversation_analysis}\n\n### RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•\n{rag_context}"
        
        return {"report_text": report_text}
        
    # --- å‚™ç”¨ï¼šç„¡ AI ç’°å¢ƒ ---
    else:
        return {"error": "ç„¡æ³•ç”Ÿæˆåˆ†æå ±å‘Šï¼šæœªæ‰¾åˆ° AI ç’°å¢ƒè¨­å®šã€‚"}

@expose
def get_detailed_report(full_conversation: list, case_id: str) -> dict:
    """
    ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Šã€ä½¿ç”¨ LLM + RAGã€‘ã€‚
    é€™æ˜¯ç¬¬äºŒéšæ®µçš„å®Œæ•´å ±å‘Šç”ŸæˆåŠŸèƒ½ã€‚
    """
    print("\n[è©³ç´°å ±å‘Šç”Ÿæˆ] é–‹å§‹ç”Ÿæˆå®Œæ•´åˆ†æå ±å‘Š...")
    
    case_data = load_case_data(case_id)
    if not case_data:
        return {"error": f"Case '{case_id}' not found"}

    # è®€å–å›é¥‹ç³»çµ±é…ç½®
    feedback_system = case_data.get("feedback_system", {})
    checklist = feedback_system.get("checklist", [])
    critical_actions = feedback_system.get("critical_actions", [])
    
    # å°‡å°è©±è½‰æ›ç‚ºæ–‡å­—æ ¼å¼
    conversation_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in full_conversation])
    
    # å°‡æª¢æŸ¥æ¸…å–®è½‰æ›ç‚ºæ–‡å­—æ ¼å¼
    checklist_text = "\n".join([f"- {item['point']} (é¡åˆ¥: {item['category']})" for item in checklist])
    
    # å°‡é—œéµè¡Œå‹•è½‰æ›ç‚ºæ–‡å­—æ ¼å¼
    critical_actions_text = "\n".join([f"- {action}" for action in critical_actions])

    # 1. ä½¿ç”¨ RAG ç³»çµ±æœå°‹ç›¸é—œè‡¨åºŠæŒ‡å¼•
    # æ ¹æ“šå°è©±å…§å®¹å‹•æ…‹ç”ŸæˆæŸ¥è©¢
    user_messages = [msg['content'] for msg in full_conversation if msg['role'] == 'user']
    conversation_summary = " ".join(user_messages)
    
    # ç”Ÿæˆå¤šå€‹ç›¸é—œæŸ¥è©¢ä¾†ç²å¾—æ›´å…¨é¢çš„çŸ¥è­˜
    rag_queries = [
        "æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹å’Œæª¢æŸ¥é †åº",
        "ECG å¿ƒé›»åœ–åœ¨èƒ¸ç—›è©•ä¼°ä¸­çš„é‡è¦æ€§",
        "STEMI å’Œä¸ç©©å®šå‹å¿ƒçµç—›çš„è¨ºæ–·æ¨™æº–",
        "èƒ¸ç—›å•è¨ºçš„ OPQRST æŠ€å·§å’Œé‡é»"
    ]
    
    # æœå°‹ä¸¦æ•´åˆ RAG çµæœï¼ŒåŒ…å«å¼•è¨»è³‡è¨Š
    rag_contexts = []
    citations = []  # ç”¨æ–¼è¿½è¹¤å¼•è¨»ä¾†æº
    
    for i, query in enumerate(rag_queries, 1):
        context = rag_system.search(query, k=2)
        if context and "RAG ç³»çµ±æœªåˆå§‹åŒ–" not in context:
            # è§£æä¾†æºè³‡è¨Š
            source_info = f"è‡¨åºŠæŒ‡å¼• {i}"
            citations.append({
                "id": i,
                "query": query,
                "source": source_info,
                "content": context
            })
            rag_contexts.append(f"### é—œæ–¼ {query} [å¼•è¨» {i}]\n{context}")
    
    combined_rag_context = "\n\n".join(rag_contexts) if rag_contexts else "æœªæ‰¾åˆ°ç›¸é—œè‡¨åºŠæŒ‡å¼•"
    
    # 2. æ§‹å»ºè©³ç´°çš„ LLM Prompt
    detailed_prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ OSCE è‡¨åºŠæ•™å¸«å’Œå¿ƒè‡Ÿç§‘å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šç”Ÿæˆä¸€ä»½è©³ç´°çš„è¨ºå¾Œåˆ†æå ±å‘Šã€‚

    ### å­¸ç”Ÿå•è¨ºè¡¨ç¾
    {conversation_text}

    ### è©•ä¼°æ¨™æº–
    **æª¢æŸ¥æ¸…å–®ï¼š**
    {checklist_text}

    **é—œéµè¡Œå‹•ï¼š**
    {critical_actions_text}

    ### ç›¸é—œè‡¨åºŠæŒ‡å¼• (RAG ç³»çµ±æä¾›)
    {combined_rag_context}

    ### ä½ çš„ä»»å‹™
    è«‹ç”Ÿæˆä¸€ä»½å°ˆæ¥­ã€è©³ç´°çš„åˆ†æå ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

    ## 1. å•è¨ºè¡¨ç¾è©•ä¼°
    - ç³»çµ±æ€§åˆ†æå­¸ç”Ÿçš„å•è¨ºæŠ€å·§
    - æŒ‡å‡ºå„ªé»å’Œä¸è¶³ä¹‹è™•
    - å¼•ç”¨å…·é«”çš„å°è©±å…§å®¹ä½œç‚ºä¾æ“š

    ## 2. è‡¨åºŠæ±ºç­–åˆ†æ
    - è©•ä¼°å­¸ç”Ÿçš„è‡¨åºŠæ€ç¶­éç¨‹
    - åˆ†ææ˜¯å¦è­˜åˆ¥å‡ºé—œéµç—‡ç‹€å’Œå±éšªå› å­
    - è©•ä¼°æ±ºç­–çš„æ™‚æ•ˆæ€§å’Œæº–ç¢ºæ€§

    ## 3. çŸ¥è­˜æ‡‰ç”¨è©•ä¼°
    - è©•ä¼°å­¸ç”Ÿå°æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹çš„ç†è§£
    - åˆ†ææ˜¯å¦éµå¾ªæ¨™æº–åŒ–å•è¨ºç¨‹åº
    - è©•ä¼°å°é—œéµæª¢æŸ¥çš„èªçŸ¥

    ## 4. æ”¹é€²å»ºè­°
    - åŸºæ–¼ RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•ï¼Œçµ¦å‡ºå…·é«”å»ºè­°
    - æä¾›å¯¦ç”¨çš„å­¸ç¿’è³‡æºå’Œç·´ç¿’æ–¹å‘
    - å»ºè­°ä¸‹ä¸€æ­¥çš„å­¸ç¿’é‡é»

    ## 5. è©•åˆ†ç¸½çµ
    - çµ¦å‡ºå„é …ç›®çš„å…·é«”è©•åˆ† (1-10åˆ†)
    - æä¾›ç¸½é«”è©•åƒ¹å’Œç­‰ç´š
    - å»ºè­°æ˜¯å¦éœ€è¦é¡å¤–ç·´ç¿’

    ### é‡è¦è¦æ±‚ï¼š
    1. å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«æ•´ä»½å ±å‘Š
    2. åœ¨å¼•ç”¨è‡¨åºŠæŒ‡å¼•æ™‚ï¼Œå¿…é ˆä½¿ç”¨ [å¼•è¨» X] çš„æ ¼å¼æ¨™è¨˜ï¼Œä¾‹å¦‚ [å¼•è¨» 1]ã€[å¼•è¨» 2] ç­‰
    3. æ¯å€‹å»ºè­°éƒ½æ‡‰è©²å¼•ç”¨ç›¸æ‡‰çš„è‡¨åºŠæŒ‡å¼•ï¼Œæ ¼å¼ç‚ºï¼šæ ¹æ“š [å¼•è¨» X] çš„æŒ‡å¼•...
    4. èªæ°£å°ˆæ¥­ä½†å‹å–„ï¼Œé©åˆé†«å­¸ç”Ÿå­¸ç¿’ä½¿ç”¨
    5. ç¢ºä¿æ‰€æœ‰é†«å­¸è¡“èªä½¿ç”¨æ­£ç¢ºçš„ç¹é«”ä¸­æ–‡
    
    ### å¼•è¨»ä½¿ç”¨ç¯„ä¾‹ï¼š
    - æ ¹æ“š [å¼•è¨» 1] çš„è¨ºæ–·æµç¨‹æŒ‡å¼•ï¼ŒECG æª¢æŸ¥æ‡‰åœ¨ 10 åˆ†é˜å…§å®Œæˆ
    - å¦‚ [å¼•è¨» 2] æ‰€è¿°ï¼Œå¿ƒé›»åœ–æ˜¯æ€¥æ€§èƒ¸ç—›è©•ä¼°çš„ç¬¬ä¸€å„ªå…ˆæª¢æŸ¥
    - æŒ‰ç…§ [å¼•è¨» 3] çš„è¨ºæ–·æ¨™æº–ï¼ŒSTEMI éœ€è¦ç«‹å³è™•ç†
    """

    messages = [{"role": "system", "content": detailed_prompt}]

    # --- è·¯ç·š A: Demo (Lemonade) ---
    if PATH_A_DEMO:
        print("[Lemonade] æ­£åœ¨ç”Ÿæˆè©³ç´°å ±å‘Š...")
        # é€™è£¡æ˜¯ä½ å¯¦éš›å‘¼å« lemonade LLM çš„åœ°æ–¹
        # response = lemonade.llm.chat(model="Qwen3-1.7B-GGUF", messages=messages)
        # return {"report_text": response.choices[0].message.content}
        report_text = f"[From Lemonade] è©³ç´°å ±å‘Šåˆ†æï¼š\n\nåŸºæ–¼ RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•ï¼š\n{combined_rag_context[:200]}...\n\né€™æ˜¯ä¸€ä»½ä¾†è‡ª Lemonade çš„è©³ç´°åˆ†æå ±å‘Š..."
        
        # æ·»åŠ åŸºæ–¼ RAG çš„å»ºè­°
        if citations:
            rag_suggestions = "\n\n## åŸºæ–¼è‡¨åºŠæŒ‡å¼•çš„å»ºè­°\n\n"
            for i, citation in enumerate(citations, 1):
                rag_suggestions += f"**æ ¹æ“š [å¼•è¨» {i}] çš„æŒ‡å¼•ï¼š**\n"
                content = citation['content']
                if 'ECG' in content or 'å¿ƒé›»åœ–' in content:
                    rag_suggestions += "- ECG å¿ƒé›»åœ–æª¢æŸ¥æ‡‰åœ¨ 10 åˆ†é˜å…§å®Œæˆï¼Œé€™æ˜¯æ€¥æ€§èƒ¸ç—›è©•ä¼°çš„ç¬¬ä¸€å„ªå…ˆæª¢æŸ¥\n"
                if 'STEMI' in content:
                    rag_suggestions += "- ç–‘ä¼¼ STEMI æ™‚æ‡‰ç«‹å³å•Ÿå‹•å¿ƒå°ç®¡åœ˜éšŠï¼Œæ™‚é–“å°±æ˜¯å¿ƒè‚Œ\n"
                if 'OPQRST' in content:
                    rag_suggestions += "- å•è¨ºæ‡‰éµå¾ª OPQRST çµæ§‹ï¼šç™¼ä½œæ™‚é–“ã€èª˜ç™¼å› å­ã€ç–¼ç—›æ€§è³ªã€æ”¾å°„ä½ç½®ã€åš´é‡ç¨‹åº¦ã€æŒçºŒæ™‚é–“\n"
                rag_suggestions += "\n"
            
            report_text += rag_suggestions
        
        return {
            "report_text": report_text,
            "citations": citations,
            "rag_queries": rag_queries
        }

    # --- è·¯ç·š B: é–‹ç™¼ (Ollama) ---
    elif PATH_B_DEVELOPMENT:
        print(f"[Ollama] æ­£åœ¨ç”Ÿæˆè©³ç´°å ±å‘Š...")
        try:
            response = OLLAMA_CLIENT.chat(
                model=os.getenv("OLLAMA_MODEL"),
                messages=messages
            )
            report_text = response['message']['content']
        except Exception as e:
            print(f"[Ollama] ç”Ÿæˆè©³ç´°å ±å‘Šå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ: {e}")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å¢å¼·ç‰ˆåˆ†æ + RAG å…§å®¹
            user_messages = [msg['content'] for msg in full_conversation if msg['role'] == 'user']
            conversation_analysis = analyze_conversation_enhanced(user_messages, checklist, critical_actions)
            report_text = f"""
# è©³ç´°è¨ºå¾Œåˆ†æå ±å‘Š

{conversation_analysis}

---

## RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•

{combined_rag_context}

---

*è¨»ï¼šæ­¤ç‚ºå‚™ç”¨è©³ç´°å ±å‘Šï¼ŒåŒ…å« RAG æœå°‹çš„è‡¨åºŠæŒ‡å¼•å…§å®¹ã€‚*
            """
        
        # å¦‚æœ LLM æ²’æœ‰ç”Ÿæˆå¼•è¨»æ¨™è¨˜ï¼Œæˆ‘å€‘æ‰‹å‹•æ·»åŠ 
        if not re.search(r'\[å¼•è¨» \d+\]', report_text) and citations:
            # åœ¨å ±å‘Šæœ«å°¾æ·»åŠ åŸºæ–¼ RAG çš„å»ºè­°
            rag_suggestions = "\n\n## åŸºæ–¼è‡¨åºŠæŒ‡å¼•çš„å»ºè­°\n\n"
            for i, citation in enumerate(citations, 1):
                rag_suggestions += f"**æ ¹æ“š [å¼•è¨» {i}] çš„æŒ‡å¼•ï¼š**\n"
                # å¾ RAG å…§å®¹ä¸­æå–é—œéµå»ºè­°
                content = citation['content']
                if 'ECG' in content or 'å¿ƒé›»åœ–' in content:
                    rag_suggestions += "- ECG å¿ƒé›»åœ–æª¢æŸ¥æ‡‰åœ¨ 10 åˆ†é˜å…§å®Œæˆï¼Œé€™æ˜¯æ€¥æ€§èƒ¸ç—›è©•ä¼°çš„ç¬¬ä¸€å„ªå…ˆæª¢æŸ¥\n"
                if 'STEMI' in content:
                    rag_suggestions += "- ç–‘ä¼¼ STEMI æ™‚æ‡‰ç«‹å³å•Ÿå‹•å¿ƒå°ç®¡åœ˜éšŠï¼Œæ™‚é–“å°±æ˜¯å¿ƒè‚Œ\n"
                if 'OPQRST' in content:
                    rag_suggestions += "- å•è¨ºæ‡‰éµå¾ª OPQRST çµæ§‹ï¼šç™¼ä½œæ™‚é–“ã€èª˜ç™¼å› å­ã€ç–¼ç—›æ€§è³ªã€æ”¾å°„ä½ç½®ã€åš´é‡ç¨‹åº¦ã€æŒçºŒæ™‚é–“\n"
                rag_suggestions += "\n"
            
            report_text += rag_suggestions
        
        return {
            "report_text": report_text,
            "citations": citations,
            "rag_queries": rag_queries
        }
        
    # --- å‚™ç”¨ï¼šç„¡ AI ç’°å¢ƒ ---
    else:
        return {"error": "ç„¡æ³•ç”Ÿæˆè©³ç´°å ±å‘Šï¼šæœªæ‰¾åˆ° AI ç’°å¢ƒè¨­å®šã€‚"}


# --- Flask è·¯ç”± (åƒ…åœ¨é–‹ç™¼æ¨¡å¼ä¸‹ä½¿ç”¨) ---
# é€™äº›è·¯ç”±æœƒå°‡å‰ç«¯çš„è«‹æ±‚ï¼Œè½‰ç™¼çµ¦ä¸Šé¢çš„æ ¸å¿ƒ AI å‡½å¼
def analyze_conversation_enhanced(user_messages: list, checklist: list, critical_actions: list) -> str:
    """å¢å¼·ç‰ˆçš„å°è©±åˆ†æï¼Œç”Ÿæˆæ›´è©³ç´°çš„å ±å‘Š"""
    conversation_text = " ".join(user_messages).lower()
    
    report_items = []
    covered_count = 0
    partial_count = 0
    
    # åˆ†ææ¯å€‹æª¢æŸ¥é …ç›®
    for item in checklist:
        keywords = item.get('keywords', [])
        matched_keywords = [kw for kw in keywords if kw.lower() in conversation_text]
        
        if len(matched_keywords) >= 2:  # å¤šå€‹é—œéµå­—åŒ¹é…
            report_items.append(f"- âœ… {item['point']}ï¼šå­¸ç”Ÿé€éæå•ã€Œ{matched_keywords[0]}ã€ç­‰æˆåŠŸå•è¨º")
            covered_count += 1
        elif len(matched_keywords) == 1:  # å–®ä¸€é—œéµå­—åŒ¹é…
            report_items.append(f"- âš ï¸ {item['point']}ï¼šå­¸ç”Ÿæœ‰ç›¸é—œæå•ã€Œ{matched_keywords[0]}ã€ï¼Œä½†å¯æ›´æ·±å…¥")
            partial_count += 1
        else:
            report_items.append(f"- âŒ {item['point']}ï¼šå­¸ç”Ÿæœªè©¢å•æ­¤é …ç›®")
    
    # åˆ†æé—œéµè¡Œå‹•
    critical_analysis = []
    for action in critical_actions:
        if any(keyword in conversation_text for keyword in ["å¿ƒé›»åœ–", "ECG", "12å°ç¨‹", "ç«‹åˆ»", "é¦¬ä¸Š", "10åˆ†"]):
            critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
        else:
            critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
    
    coverage_percentage = int((covered_count / len(checklist)) * 100) if checklist else 0
    
    return f"""### è¨ºå¾Œåˆ†æå ±å‘Š

**å•è¨ºè¦†è“‹ç‡ï¼š{coverage_percentage}% ({covered_count}/{len(checklist)})**
**å®Œæ•´é …ç›®ï¼š{covered_count} | éƒ¨åˆ†é …ç›®ï¼š{partial_count} | æœªè¦†è“‹ï¼š{len(checklist) - covered_count - partial_count}**

**è©³ç´°è©•ä¼°ï¼š**
{chr(10).join(report_items)}

**é—œéµè¡Œå‹•è©•ä¼°ï¼š**
{chr(10).join(critical_analysis)}

### ç¸½çµèˆ‡å»ºè­°

**å„ªé»ï¼š**
- å•è¨ºè¦†è“‹ç‡é” {coverage_percentage}%
- å­¸ç”Ÿå±•ç¾äº†åŸºæœ¬çš„å•è¨ºæŠ€å·§
- èƒ½å¤ èˆ‡ç—…äººå»ºç«‹è‰¯å¥½çš„æºé€š

**æ”¹é€²å»ºè­°ï¼š**
1. **ç³»çµ±æ€§å•è¨º**ï¼šå»ºè­°æŒ‰ç…§ OPQRST çµæ§‹é€²è¡Œå•è¨º
2. **æ·±å…¥æ¢ç´¢**ï¼šå°æ–¼å·²è§¸åŠçš„ä¸»é¡Œï¼Œå¯ä»¥é€²ä¸€æ­¥æ·±å…¥è©¢å•
3. **é—œéµæ±ºç­–**ï¼šåŠ å¼·è‡¨åºŠæ±ºç­–èƒ½åŠ›ï¼ŒåŠæ™‚æå‡ºé—œéµæª¢æŸ¥
4. **å®Œæ•´æ€§**ï¼šæ³¨æ„å•è¨ºçš„å…¨é¢æ€§ï¼Œé¿å…éºæ¼é‡è¦é …ç›®

**å…·é«”å»ºè­°ï¼š**
- å¤šç·´ç¿’æ¨™æº–åŒ–å•è¨ºæµç¨‹
- åŠ å¼·å°é—œéµç—‡ç‹€çš„è­˜åˆ¥èƒ½åŠ›
- æå‡è‡¨åºŠæ±ºç­–çš„æ™‚æ•ˆæ€§

*è¨»ï¼šæ­¤ç‚ºå¢å¼·ç‰ˆåˆ†æå ±å‘Šï¼Œæä¾›æ›´è©³ç´°çš„è©•ä¼°å’Œå»ºè­°ã€‚*"""

def analyze_conversation_simple(user_messages: list, checklist: list) -> str:
    """ç°¡å–®çš„å°è©±åˆ†æï¼Œç”ŸæˆåŸºæœ¬å ±å‘Š"""
    conversation_text = " ".join(user_messages).lower()
    
    report_items = []
    covered_count = 0
    
    for item in checklist:
        keywords = item.get('keywords', [])
        if any(keyword.lower() in conversation_text for keyword in keywords):
            report_items.append(f"- âœ… {item['point']}ï¼šå­¸ç”Ÿæœ‰ç›¸é—œæå•")
            covered_count += 1
        else:
            report_items.append(f"- âŒ {item['point']}ï¼šå­¸ç”Ÿæœªè©¢å•æ­¤é …ç›®")
    
    coverage_percentage = int((covered_count / len(checklist)) * 100) if checklist else 0
    
    return f"""### è¨ºå¾Œåˆ†æå ±å‘Š

**å•è¨ºè¦†è“‹ç‡ï¼š{coverage_percentage}% ({covered_count}/{len(checklist)})**

**è©³ç´°è©•ä¼°ï¼š**
{chr(10).join(report_items)}

### ç¸½çµèˆ‡å»ºè­°

æœ¬æ¬¡å•è¨ºè¦†è“‹äº† {coverage_percentage}% çš„æª¢æŸ¥é …ç›®ã€‚å»ºè­°å­¸ç”Ÿï¼š
1. åŠ å¼·æœªè¦†è“‹é …ç›®çš„å•è¨ºæŠ€å·§
2. æ³¨æ„å•è¨ºçš„ç³»çµ±æ€§å’Œå®Œæ•´æ€§
3. å¤šç·´ç¿’æ¨™æº–åŒ–çš„å•è¨ºæµç¨‹

*è¨»ï¼šæ­¤ç‚ºç°¡åŒ–ç‰ˆåˆ†æå ±å‘Šï¼Œå®Œæ•´ç‰ˆéœ€è¦æ›´å¤šæ™‚é–“è™•ç†ã€‚*"""

def calculate_coverage(history: list, case_id: str) -> int:
    """è¨ˆç®—å•è¨ºè¦†è“‹ç‡"""
    case_data = load_case_data(case_id)
    if not case_data:
        return 0
    
    feedback_system = case_data.get("feedback_system", {})
    checklist = feedback_system.get("checklist", [])
    
    if not checklist:
        return 0
    
    # å°‡å°è©±æ­·å²è½‰æ›ç‚ºæ–‡å­—
    conversation_text = " ".join([msg['content'] for msg in history if msg['role'] == 'user'])
    conversation_text = conversation_text.lower()
    
    covered_items = 0
    total_items = len(checklist)
    
    for item in checklist:
        # æª¢æŸ¥é—œéµå­—æ˜¯å¦åœ¨å°è©±ä¸­å‡ºç¾
        keywords = item.get('keywords', [])
        if any(keyword.lower() in conversation_text for keyword in keywords):
            covered_items += 1
    
    # è¨ˆç®—è¦†è“‹ç‡ç™¾åˆ†æ¯”
    coverage_percentage = int((covered_items / total_items) * 100) if total_items > 0 else 0
    return min(coverage_percentage, 100)  # ç¢ºä¿ä¸è¶…é 100%

@app.route('/ask_patient', methods=['POST'])
def ask_patient_route():
    data = request.json
    history = data.get('history', [])
    case_id = data.get('case_id')
    
    result = ask_patient(history=history, case_id=case_id)
    coverage = calculate_coverage(history, case_id)
    
    return jsonify({"reply": result, "coverage": coverage})

@app.route('/get_feedback_report', methods=['POST'])
def get_feedback_report_route():
    data = request.json
    result = get_feedback_report(full_conversation=data.get('full_conversation'), case_id=data.get('case_id'))
    return jsonify(result)

@app.route('/get_detailed_report', methods=['POST'])
def get_detailed_report_route():
    """ç”Ÿæˆè©³ç´°å ±å‘Šçš„ API ç«¯é»ï¼Œä½¿ç”¨ LLM + RAG"""
    data = request.json
    result = get_detailed_report(full_conversation=data.get('full_conversation'), case_id=data.get('case_id'))
    return jsonify(result)

# --- å•Ÿå‹•å™¨ ---
# åªæœ‰åœ¨ã€Œé–‹ç™¼æ¨¡å¼ã€ä¸‹ï¼Œé€™å€‹ Flask ä¼ºæœå™¨æ‰æœƒç›´æ¥è¢«å•Ÿå‹•ã€‚
# åœ¨ã€ŒDemo æ¨¡å¼ã€ä¸‹ï¼Œé€™å€‹æª”æ¡ˆæœƒè¢« Lemonade ä½œç‚ºæ¨¡çµ„è¼‰å…¥ï¼Œä¸æœƒåŸ·è¡Œé€™ä¸€æ®µã€‚
if __name__ == '__main__' and not PATH_A_DEMO:
    if PATH_B_DEVELOPMENT:
        print(f"Flask é–‹ç™¼ä¼ºæœå™¨æ­£åœ¨ http://127.0.0.1:5002 ä¸Šé‹è¡Œ...")
        app.run(host='0.0.0.0', port=5002, debug=True)
    else:
        print("ç„¡æ³•å•Ÿå‹•ï¼šæœªæ‰¾åˆ° Lemonade æˆ– Ollama è¨­å®šã€‚è«‹æª¢æŸ¥ä½ çš„ç’°å¢ƒã€‚")