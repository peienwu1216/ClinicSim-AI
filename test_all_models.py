# ä½¿ç”¨ call_AI.py çš„æ–¹æ³•æµ‹è¯•æ‰€æœ‰æ¨¡å‹
from call_AI import call_ai
import json

def test_model(model_name, test_message="ä½ å¥½ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ä¸€å€‹ç°¡å–®çš„å•é¡Œï¼š1+1ç­‰æ–¼å¤šå°‘ï¼Ÿ"):
    """
    æ¸¬è©¦æŒ‡å®šçš„æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    try:
        print(f"ğŸ§ª æ¸¬è©¦æ¨¡å‹: {model_name}")
        print(f"ğŸ“ æ¸¬è©¦è¨Šæ¯: {test_message}")
        print("-" * 60)
        
        # ä½¿ç”¨ call_AI.py çš„æ–¹æ³•ï¼Œä½†éœ€è¦ä¸´æ—¶ä¿®æ”¹æ¨¡å‹
        # ç”±äº call_AI.py ç¡¬ç¼–ç äº†æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªä¸´æ—¶å‡½æ•°
        content = call_ai_with_model(model_name, test_message)
        
        print(f"âœ… å›æ‡‰æˆåŠŸ:")
        print(f"ğŸ“¤ {content}")
        print(f"â±ï¸  å›æ‡‰æ™‚é–“: æ­£å¸¸")
        return True, content
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False, str(e)

def call_ai_with_model(model_name: str, message: str) -> str:
    """
    ä½¿ç”¨æŒ‡å®šæ¨¡å‹è°ƒç”¨ AI
    """
    from openai import OpenAI
    
    # Initialize the client to use Lemonade Server
    client = OpenAI(
        base_url="http://127.0.0.1:8080/api/v1",
        api_key="lemonade"  # required but unused
    )

    # Create a chat completion with specified model
    completion = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "user", "content": message}
        ]
    )

    return completion.choices[0].message.content

def main():
    """
    æ¸¬è©¦æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    """
    models = [
        "Qwen2.5-0.5B-Instruct-CPU",
        "Llama-3.2-1B-Instruct-Hybrid", 
        "Qwen-2.5-7B-Instruct-Hybrid",
        "squeeze-ai-lab/TinyAgent-1.1B"
    ]
    
    print("ğŸš€ é–‹å§‹æ¸¬è©¦æ‰€æœ‰å¯ç”¨æ¨¡å‹")
    print("=" * 80)
    
    results = {}
    
    for model in models:
        success, response = test_model(model)
        results[model] = {
            'success': success,
            'response': response
        }
        print("\n" + "=" * 80 + "\n")
    
    # ç¸½çµçµæœ
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    print("=" * 80)
    
    successful_models = []
    failed_models = []
    
    for model, result in results.items():
        if result['success']:
            successful_models.append(model)
            print(f"âœ… {model} - æ­£å¸¸é‹ä½œ")
        else:
            failed_models.append(model)
            print(f"âŒ {model} - å¤±æ•— ({result['response']})")
    
    print(f"\nğŸ¯ å»ºè­°:")
    if successful_models:
        print(f"âœ… å¯ç”¨çš„æ¨¡å‹: {', '.join(successful_models)}")
        print(f"ğŸ’¡ æ¨è–¦ä½¿ç”¨: {successful_models[0]} (ç¬¬ä¸€å€‹æˆåŠŸçš„æ¨¡å‹)")
        
        # ç‰¹åˆ¥æ¨è–¦
        if "Qwen-2.5-7B-Instruct-Hybrid" in successful_models:
            print(f"ğŸŒŸ æœ€ä½³é¸æ“‡: Qwen-2.5-7B-Instruct-Hybrid (7B åƒæ•¸ï¼Œæ€§èƒ½æœ€ä½³)")
        elif "Qwen2.5-0.5B-Instruct-CPU" in successful_models:
            print(f"âš¡ å¿«é€Ÿé¸æ“‡: Qwen2.5-0.5B-Instruct-CPU (0.5B åƒæ•¸ï¼Œé€Ÿåº¦æœ€å¿«)")
    else:
        print("âŒ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè«‹æª¢æŸ¥ Lemonade Server ç‹€æ…‹")
    
    if failed_models:
        print(f"âš ï¸  å¤±æ•—çš„æ¨¡å‹: {', '.join(failed_models)}")

if __name__ == "__main__":
    main()
