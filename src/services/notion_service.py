"""
Notion API æ•´åˆæœå‹™
"""

import requests
import json
import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path

from ..config.settings import get_settings
from ..exceptions.notion_exceptions import NotionAPIError, NotionAuthError, NotionDatabaseError


class NotionService:
    """Notion API æ•´åˆæœå‹™"""
    
    def __init__(self, settings=None):
        self.settings = settings or get_settings()
        self.api_base_url = "https://api.notion.com/v1"
        self.api_key = getattr(self.settings, 'notion_api_key', None)
        self.database_id = getattr(self.settings, 'notion_database_id', None)
        
        # API è«‹æ±‚æ¨™é ­
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Notion-Version": "2022-06-28"
        }
    
    def is_configured(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å·²é…ç½® Notion API"""
        return bool(self.api_key and self.database_id)
    
    def test_connection(self) -> Tuple[bool, str]:
        """æ¸¬è©¦ Notion API é€£ç·š"""
        if not self.is_configured():
            return False, "Notion API æœªé…ç½®ï¼Œè«‹å…ˆè¨­å®š API Key å’Œ Database ID"
        
        try:
            # æ¸¬è©¦ API Key æœ‰æ•ˆæ€§
            response = requests.get(
                f"{self.api_base_url}/users/me",
                headers=self.headers,
                timeout=10
            )
            
            if response.status_code == 401:
                return False, "Notion API Key ç„¡æ•ˆï¼Œè«‹æª¢æŸ¥è¨­å®š"
            elif response.status_code == 200:
                # æ¸¬è©¦ Database å­˜å–æ¬Šé™
                db_response = requests.get(
                    f"{self.api_base_url}/databases/{self.database_id}",
                    headers=self.headers,
                    timeout=10
                )
                
                if db_response.status_code == 404:
                    return False, "Notion Database ä¸å­˜åœ¨æˆ–ç„¡å­˜å–æ¬Šé™"
                elif db_response.status_code == 200:
                    return True, "é€£ç·šæˆåŠŸ"
                else:
                    return False, f"Database å­˜å–éŒ¯èª¤: {db_response.status_code}"
            else:
                return False, f"API é€£ç·šéŒ¯èª¤: {response.status_code}"
                
        except requests.exceptions.RequestException as e:
            return False, f"ç¶²è·¯é€£ç·šéŒ¯èª¤: {str(e)}"
    
    def create_learning_record(self, report_path: str, case_data: Dict[str, Any]) -> Tuple[bool, str]:
        """å‰µå»ºå­¸ç¿’è¨˜éŒ„åˆ° Notion Database"""
        try:
            # è§£æå ±å‘Šå…§å®¹
            parsed_report = self._parse_report_file(report_path)
            
            # è½‰æ›ç‚º Notion æ ¼å¼
            notion_data = self._format_for_notion(parsed_report, case_data)
            
            # ç™¼é€åˆ° Notion
            response = requests.post(
                f"{self.api_base_url}/pages",
                headers=self.headers,
                json=notion_data,
                timeout=30
            )
            
            if response.status_code == 200:
                page_data = response.json()
                page_url = page_data.get('url', '')
                return True, f"å­¸ç¿’è¨˜éŒ„å·²æˆåŠŸå‰µå»ºåˆ° Notionï¼\né é¢é€£çµ: {page_url}"
            else:
                error_msg = response.json().get('message', 'æœªçŸ¥éŒ¯èª¤')
                return False, f"å‰µå»ºå¤±æ•—: {error_msg}"
                
        except Exception as e:
            return False, f"è™•ç†å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    def _parse_report_file(self, report_path: str) -> Dict[str, Any]:
        """è§£æå ±å‘Šæª”æ¡ˆå…§å®¹"""
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–åŸºæœ¬è³‡è¨Š
            parsed = {
                'case_id': self._extract_field(content, r'æ¡ˆä¾‹ ID\*\*: (.+)'),
                'report_type': self._extract_field(content, r'å ±å‘Šé¡å‹\*\*: (.+)'),
                'generated_time': self._extract_field(content, r'ç”Ÿæˆæ™‚é–“\*\*: (.+)'),
                'coverage': self._extract_field(content, r'å•è¨ºè¦†è“‹ç‡\*\*: (.+)'),
                'message_count': self._extract_field(content, r'å°è©±é•·åº¦\*\*: (.+)'),
                'citation_count': self._extract_field(content, r'å¼•è¨»æ•¸é‡\*\*: (.+)'),
                'rag_queries': self._extract_field(content, r'RAG æŸ¥è©¢\*\*: (.+)'),
                'full_content': content
            }
            
            # æå–è©•åˆ†è³‡è¨Š
            scores = self._extract_scores(content)
            parsed.update(scores)
            
            # æå–å»ºè­°å…§å®¹
            suggestions = self._extract_suggestions(content)
            parsed.update(suggestions)
            
            return parsed
            
        except Exception as e:
            raise NotionAPIError(f"è§£æå ±å‘Šæª”æ¡ˆå¤±æ•—: {str(e)}")
    
    def _extract_field(self, content: str, pattern: str) -> str:
        """ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–æ¬„ä½å€¼"""
        match = re.search(pattern, content)
        return match.group(1).strip() if match else ""
    
    def _extract_scores(self, content: str) -> Dict[str, Any]:
        """æå–è©•åˆ†è³‡è¨Š"""
        scores = {}
        
        # æå–å„é …è©•åˆ†
        score_patterns = {
            'interview_score': r'å•è¨ºè¡¨ç¾è©•ä¼°ï¼š(\d+(?:\.\d+)?)/10',
            'decision_score': r'è‡¨åºŠæ±ºç­–åˆ†æï¼š(\d+(?:\.\d+)?)/10',
            'knowledge_score': r'çŸ¥è­˜æ‡‰ç”¨è©•ä¼°ï¼š(\d+(?:\.\d+)?)/10',
            'total_score': r'ç¸½é«”è©•åƒ¹ç‚º (\d+(?:\.\d+)?)/10'
        }
        
        for key, pattern in score_patterns.items():
            match = re.search(pattern, content)
            if match:
                try:
                    scores[key] = float(match.group(1))
                except ValueError:
                    scores[key] = 0.0
            else:
                scores[key] = 0.0
        
        return scores
    
    def _extract_suggestions(self, content: str) -> Dict[str, str]:
        """æå–å­¸ç¿’å»ºè­°"""
        suggestions = {}
        
        # æå–æ”¹é€²å»ºè­°
        improvement_match = re.search(r'\*\*4\. æ”¹é€²å»ºè­°\*\*\n\n(.*?)\n\n\*\*5\.', content, re.DOTALL)
        if improvement_match:
            suggestions['improvement_suggestions'] = improvement_match.group(1).strip()
        
        # æå–ç¸½çµå»ºè­°
        summary_match = re.search(r'\*\*å»ºè­°\*\*\n\n(.*?)\n\nç¸½çµ', content, re.DOTALL)
        if summary_match:
            suggestions['summary_suggestions'] = summary_match.group(1).strip()
        
        return suggestions
    
    def _format_for_notion(self, parsed_report: Dict[str, Any], case_data: Dict[str, Any]) -> Dict[str, Any]:
        """å°‡è§£æçš„å ±å‘Šè³‡æ–™è½‰æ›ç‚º Notion API æ ¼å¼"""
        
        # æ§‹å»º Notion é é¢è³‡æ–™
        notion_data = {
            "parent": {
                "database_id": self.database_id
            },
            "properties": {
                # æ¨™é¡Œæ¬„ä½
                "Name": {
                    "title": [
                        {
                            "text": {
                                "content": case_data.get('case_title', f"å­¸ç¿’è¨˜éŒ„ - {parsed_report['case_id']}")
                            }
                        }
                    ]
                },
                
                # æ—¥æœŸæ¬„ä½
                "å­¸ç¿’æ—¥æœŸ": {
                    "date": {
                        "start": datetime.now().isoformat()
                    }
                },
                
                # æ¡ˆä¾‹é¡å‹
                "æ¡ˆä¾‹é¡å‹": {
                    "select": {
                        "name": self._extract_case_type(case_data)
                    }
                },
                
                # è©•åˆ†æ¬„ä½
                "å•è¨ºè¡¨ç¾": {
                    "number": parsed_report.get('interview_score', 0)
                },
                
                "è‡¨åºŠæ±ºç­–": {
                    "number": parsed_report.get('decision_score', 0)
                },
                
                "çŸ¥è­˜æ‡‰ç”¨": {
                    "number": parsed_report.get('knowledge_score', 0)
                },
                
                "ç¸½é«”è©•åƒ¹": {
                    "number": parsed_report.get('total_score', 0)
                },
                
                # è¤‡ç¿’ç‹€æ…‹
                "è¤‡ç¿’ç‹€æ…‹": {
                    "select": {
                        "name": "å¾…è¤‡ç¿’"
                    }
                }
            },
            
            # é é¢å…§å®¹
            "children": [
                {
                    "object": "block",
                    "type": "heading_2",
                    "heading_2": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": "ğŸ“Š å­¸ç¿’è¡¨ç¾æ‘˜è¦"
                                }
                            }
                        ]
                    }
                },
                {
                    "object": "block",
                    "type": "bulleted_list_item",
                    "bulleted_list_item": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": f"å•è¨ºè¦†è“‹ç‡: {parsed_report.get('coverage', 'N/A')}"
                                }
                            }
                        ]
                    }
                },
                {
                    "object": "block",
                    "type": "bulleted_list_item",
                    "bulleted_list_item": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": f"å°è©±é•·åº¦: {parsed_report.get('message_count', 'N/A')} æ¢è¨Šæ¯"
                                }
                            }
                        ]
                    }
                },
                {
                    "object": "block",
                    "type": "bulleted_list_item",
                    "bulleted_list_item": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": f"å¼•è¨»ä¾†æº: {parsed_report.get('citation_count', 'N/A')} å€‹"
                                }
                            }
                        ]
                    }
                }
            ]
        }
        
        # æ·»åŠ æ”¹é€²å»ºè­°
        if parsed_report.get('improvement_suggestions'):
            notion_data["children"].extend([
                {
                    "object": "block",
                    "type": "heading_2",
                    "heading_2": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": "ğŸ¯ æ”¹é€²å»ºè­°"
                                }
                            }
                        ]
                    }
                },
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": parsed_report['improvement_suggestions']
                                }
                            }
                        ]
                    }
                }
            ])
        
        # æ·»åŠ å®Œæ•´å ±å‘Šå…§å®¹ï¼ˆåˆ†æ®µè™•ç†ä»¥é¿å…é•·åº¦é™åˆ¶ï¼‰
        notion_data["children"].extend([
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {
                                "content": "ğŸ“‹ å®Œæ•´å­¸ç¿’å ±å‘Š"
                            }
                        }
                    ]
                }
            }
        ])
        
        # å°‡é•·å…§å®¹åˆ†æ®µè™•ç†
        full_content = parsed_report['full_content']
        content_chunks = self._split_content_by_length(full_content, 1800)  # ç•™ä¸€äº›ç·©è¡
        
        for i, chunk in enumerate(content_chunks):
            notion_data["children"].append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {
                                "content": chunk
                            }
                        }
                    ]
                }
            })
        
        return notion_data
    
    def _split_content_by_length(self, content: str, max_length: int) -> List[str]:
        """å°‡å…§å®¹æŒ‰é•·åº¦åˆ†æ®µï¼Œé¿å…è¶…å‡º Notion API é™åˆ¶"""
        if len(content) <= max_length:
            return [content]
        
        chunks = []
        current_chunk = ""
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        
        for paragraph in paragraphs:
            # å¦‚æœå–®å€‹æ®µè½å°±è¶…éé™åˆ¶ï¼Œéœ€è¦é€²ä¸€æ­¥åˆ†å‰²
            if len(paragraph) > max_length:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                
                # æŒ‰å¥å­åˆ†å‰²é•·æ®µè½
                sentences = paragraph.split('ã€‚')
                for sentence in sentences:
                    if len(current_chunk + sentence + 'ã€‚') <= max_length:
                        current_chunk += sentence + 'ã€‚'
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = sentence + 'ã€‚'
            else:
                # æª¢æŸ¥æ·»åŠ é€™å€‹æ®µè½æ˜¯å¦æœƒè¶…å‡ºé™åˆ¶
                if len(current_chunk + '\n\n' + paragraph) <= max_length:
                    if current_chunk:
                        current_chunk += '\n\n' + paragraph
                    else:
                        current_chunk = paragraph
                else:
                    # ä¿å­˜ç•¶å‰å¡Šä¸¦é–‹å§‹æ–°å¡Š
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = paragraph
        
        # æ·»åŠ æœ€å¾Œä¸€å¡Š
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _extract_case_type(self, case_data: Dict[str, Any]) -> str:
        """å¾æ¡ˆä¾‹è³‡æ–™ä¸­æå–æ¡ˆä¾‹é¡å‹"""
        if not isinstance(case_data, dict):
            return 'å…¶ä»–'
            
        station_info = case_data.get('station_info', {})
        station_type = station_info.get('type', '')
        
        if 'å…§ç§‘' in station_type:
            return 'å…§ç§‘'
        elif 'å¤–ç§‘' in station_type:
            return 'å¤–ç§‘'
        elif 'æ€¥è¨º' in station_type:
            return 'æ€¥è¨º'
        elif 'å…’ç§‘' in station_type:
            return 'å…’ç§‘'
        else:
            return 'å…¶ä»–'
    
    def get_database_schema(self) -> Dict[str, Any]:
        """ç²å– Database çµæ§‹è³‡è¨Š"""
        if not self.is_configured():
            return {}
        
        try:
            response = requests.get(
                f"{self.api_base_url}/databases/{self.database_id}",
                headers=self.headers,
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {}
                
        except Exception:
            return {}
