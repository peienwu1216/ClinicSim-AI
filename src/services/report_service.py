"""
å ±å‘Šç”Ÿæˆæœå‹™
"""

import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

from ..models.conversation import Conversation, MessageRole
from ..models.case import Case
from ..models.report import Report, ReportType, Citation
from ..services.ai_service import get_ai_service
from ..services.rag_service import RAGService
from ..services.case_service import CaseService
from ..services.scoring_service import ScoringService
from ..services.notion_service import NotionService
from ..services.map_reduce_service import MapReduceService
from ..config.settings import get_settings
from ..utils.file_utils import save_report_to_file, generate_report_filename


class ReportService:
    """å ±å‘Šç”Ÿæˆæœå‹™"""
    
    def __init__(self, settings=None, case_service=None, ai_service=None, rag_service=None, scoring_service=None, notion_service=None, map_reduce_service=None):
        self.settings = settings or get_settings()
        self.case_service = case_service or CaseService(self.settings)
        self.ai_service = ai_service or get_ai_service(self.settings)
        self.rag_service = rag_service or RAGService(self.settings)
        self.scoring_service = scoring_service or ScoringService(self.settings)
        self.notion_service = notion_service or NotionService(self.settings)
        self.map_reduce_service = map_reduce_service or MapReduceService(self.settings, self.ai_service)
    
    def generate_feedback_report(self, conversation: Conversation) -> Report:
        """ç”Ÿæˆå³æ™‚å›é¥‹å ±å‘Š"""
        case = self.case_service.get_case(conversation.case_id)
        if not case:
            raise ValueError(f"Case not found: {conversation.case_id}")
        
        # ç¢ºä¿è¦†è“‹ç‡æ˜¯æœ€æ–°çš„
        from ..services.conversation_service import ConversationService
        conversation_service = ConversationService(self.settings)
        conversation_service._update_conversation_metrics(conversation, case)
        
        # ä½¿ç”¨æ–°çš„çµæ§‹åŒ–è©•åˆ†ç³»çµ±
        try:
            scoring_result = self.scoring_service.score_conversation(conversation)
            # ç”ŸæˆåŸºæœ¬åˆ†æå ±å‘Šï¼ˆåŒ…å«æ–°è©•åˆ†ï¼‰
            report_content = self._generate_enhanced_analysis(conversation, case, scoring_result)
        except Exception as e:
            print(f"[ERROR] è©•åˆ†ç³»çµ±éŒ¯èª¤ï¼Œä½¿ç”¨åŸºæœ¬åˆ†æ: {e}")
            # å¦‚æœè©•åˆ†ç³»çµ±å‡ºéŒ¯ï¼Œä½¿ç”¨åŸºæœ¬åˆ†æ
            report_content = self._generate_basic_analysis(conversation, case)
        
        # å³æ™‚å›é¥‹å ±å‘Šä¸åŒ…å« RAG æ–‡ç»æ‘˜è¦ï¼Œä¿æŒç°¡æ½”
        
        report = Report(
            report_type=ReportType.FEEDBACK,
            content=report_content,
            case_id=conversation.case_id,
            coverage=conversation.coverage,
            metadata={
                "generated_at": datetime.now().isoformat(),
                "conversation_length": len(conversation.messages)
            }
        )
        
        conversation.mark_report_generated()
        
        # å„²å­˜å ±å‘Šåˆ°æª”æ¡ˆ
        self._save_report_to_file(report)
        
        return report
    
    def generate_detailed_report(self, conversation: Conversation) -> Report:
        """ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Šï¼ˆä½¿ç”¨ LLM + RAGï¼‰"""
        case = self.case_service.get_case(conversation.case_id)
        if not case:
            raise ValueError(f"Case not found: {conversation.case_id}")
        
        # å…ˆç”Ÿæˆåˆæ­¥åˆ†æå ±å‘Š
        initial_feedback = self._generate_basic_analysis(conversation, case)
        
        # åŸºæ–¼åˆæ­¥å›é¥‹å…§å®¹ç”Ÿæˆæ›´ç²¾æº–çš„ RAG æŸ¥è©¢
        rag_queries = self._generate_queries_from_feedback(initial_feedback)
        
        citations = []
        if self.rag_service.is_available():
            # ä½¿ç”¨æ–°çš„ search_with_citations æ–¹æ³•ç”Ÿæˆå¸¶æœ‰å®Œæ•´ä¾†æºè³‡è¨Šçš„å¼•è¨»
            citations = self.rag_service.search_with_citations(rag_queries, k=2)
        
        # ç”Ÿæˆè©³ç´°å ±å‘Šå…§å®¹
        report_content = self._generate_detailed_analysis_with_llm(
            conversation, case, citations
        )
        
        report = Report(
            report_type=ReportType.DETAILED,
            content=report_content,
            case_id=conversation.case_id,
            citations=citations,
            rag_queries=rag_queries,
            coverage=conversation.coverage,
            metadata={
                "generated_at": datetime.now().isoformat(),
                "conversation_length": len(conversation.messages),
                "rag_available": self.rag_service.is_available(),
                "citations_count": len(citations)
            }
        )
        
        conversation.mark_detailed_report_generated()
        
        # å„²å­˜å ±å‘Šåˆ°æª”æ¡ˆ
        file_path = self._save_report_to_file(report)
        
        # å°‡æª”æ¡ˆè·¯å¾‘æ·»åŠ åˆ°å ±å‘Šå…ƒè³‡æ–™
        if file_path:
            report.metadata['file_path'] = file_path
            report.metadata['filename'] = Path(file_path).name
        
        return report
    
    def _generate_basic_analysis(self, conversation: Conversation, case: Case) -> str:
        """ç”ŸæˆåŸºæœ¬åˆ†æå ±å‘Šï¼ˆä¸ä½¿ç”¨ LLMï¼‰"""
        checklist = case.get_feedback_checklist()
        critical_actions = case.get_critical_actions()
        user_messages = conversation.get_user_messages()
        
        # å‰µå»ºå°è©±æ–‡å­—å…§å®¹ç”¨æ–¼é—œéµå­—åŒ¹é…
        conversation_text = " ".join([msg.content for msg in user_messages if hasattr(msg, 'content')])
        
        # ä½¿ç”¨å°è©±æœå‹™ä¸­å·²ç¶“è¨ˆç®—å¥½çš„è¦†è“‹é …ç›®
        covered_items = set(conversation.covered_items)
        partially_covered_items = set(conversation.partially_covered_items)
        
        report_items = []
        covered_count = len(covered_items)
        partial_count = len(partially_covered_items)
        
        for item in checklist:
            item_id = item.get('id', '')
            item_point = item.get('point', '')
            
            if item_id in covered_items:
                report_items.append(f"- âœ… {item_point}ï¼šå­¸ç”Ÿå·²å®Œæ•´è©¢å•æ­¤é …ç›®")
            elif item_id in partially_covered_items:
                report_items.append(f"- âš ï¸ {item_point}ï¼šå­¸ç”Ÿæœ‰ç›¸é—œæå•ï¼Œä½†å¯æ›´æ·±å…¥")
            else:
                report_items.append(f"- âŒ {item_point}ï¼šå­¸ç”Ÿæœªè©¢å•æ­¤é …ç›®")
        
        # åˆ†æé—œéµè¡Œå‹•
        critical_analysis = []
        for action in critical_actions:
            # é‡å°ä¸åŒçš„é—œéµè¡Œå‹•ä½¿ç”¨ä¸åŒçš„é—œéµå­—åŒ¹é…
            if "ECG" in action or "å¿ƒé›»åœ–" in action:
                # ECGç›¸é—œè¡Œå‹•çš„é—œéµå­—
                ecg_keywords = ["å¿ƒé›»åœ–", "ECG", "12å°ç¨‹", "12å°", "ç«‹åˆ»", "é¦¬ä¸Š", "ç«‹å³", "10åˆ†", "ååˆ†"]
                if any(keyword in conversation_text for keyword in ecg_keywords):
                    critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
                else:
                    critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
            elif "Troponin" in action or "å¿ƒè‚Œéˆ£è›‹ç™½" in action:
                # Troponinç›¸é—œè¡Œå‹•çš„é—œéµå­—
                troponin_keywords = ["troponin", "å¿ƒè‚Œéˆ£è›‹ç™½", "å¿ƒè‚Œé…µç´ ", "æŠ½è¡€", "æª¢é©—", "è¡€æ¶²"]
                if any(keyword in conversation_text for keyword in troponin_keywords):
                    critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
                else:
                    critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
            else:
                # å…¶ä»–é—œéµè¡Œå‹•çš„é€šç”¨åŒ¹é…
                if any(keyword in conversation_text for keyword in ["å¿ƒé›»åœ–", "ECG", "12å°ç¨‹", "ç«‹åˆ»", "é¦¬ä¸Š", "10åˆ†"]):
                    critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
                else:
                    critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
        
        coverage_percentage = conversation.coverage
        
        return f"""### è¨ºå¾Œåˆ†æå ±å‘Š

**å•è¨ºè¦†è“‹ç‡ï¼š{coverage_percentage}% ({covered_count + partial_count}/{len(checklist)})**
**å®Œæ•´é …ç›®ï¼š{covered_count} | éƒ¨åˆ†é …ç›®ï¼š{partial_count} | æœªè¦†è“‹ï¼š{len(checklist) - covered_count - partial_count}**

**è©³ç´°è©•ä¼°ï¼š**
{chr(10).join(report_items)}

**é—œéµè¡Œå‹•è©•ä¼°ï¼š**
{chr(10).join(critical_analysis)}

### ç¸½çµèˆ‡å»ºè­°

**å„ªé»ï¼š**
- å•è¨ºè¦†è“‹ç‡é” {coverage_percentage}%ï¼Œå…±è¦†è“‹ {covered_count + partial_count} å€‹é …ç›®
- å­¸ç”Ÿå±•ç¾äº†åŸºæœ¬çš„å•è¨ºæŠ€å·§
- èƒ½å¤ èˆ‡ç—…äººå»ºç«‹è‰¯å¥½çš„æºé€š

**æ”¹é€²å»ºè­°ï¼š**
1. **ç³»çµ±æ€§å•è¨º**ï¼šå»ºè­°æŒ‰ç…§ OPQRST çµæ§‹é€²è¡Œå•è¨º
2. **æ·±å…¥æ¢ç´¢**ï¼šå°æ–¼å·²è§¸åŠçš„ä¸»é¡Œï¼Œå¯ä»¥é€²ä¸€æ­¥æ·±å…¥è©¢å•
3. **é—œéµæ±ºç­–**ï¼šåŠ å¼·è‡¨åºŠæ±ºç­–èƒ½åŠ›ï¼ŒåŠæ™‚æå‡ºé—œéµæª¢æŸ¥
4. **å®Œæ•´æ€§**ï¼šæ³¨æ„å•è¨ºçš„å…¨é¢æ€§ï¼Œé¿å…éºæ¼é‡è¦é …ç›®

**å…·é«”å»ºè­°ï¼š**
- å¤šç·´ç¿’æ¨™æº–åŒ–å•è¨ºæµç¨‹
- åŠ å¼·å°é—œéµç—‡ç‹€çš„è­˜åˆ¥èƒ½åŠ›
- æå‡è‡¨åºŠæ±ºç­–çš„æ™‚æ•ˆæ€§

*è¨»ï¼šæ­¤ç‚ºå³æ™‚åˆ†æå ±å‘Šï¼Œè©³ç´°å ±å‘Šè«‹é»æ“Šã€Œç”Ÿæˆå®Œæ•´å ±å‘Šã€æŒ‰éˆ•ã€‚*"""
    
    def _generate_detailed_analysis_with_llm(self, conversation: Conversation, case: Case, citations: List[Citation]) -> str:
        """ä½¿ç”¨ Map-Reduce ç­–ç•¥ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Šï¼ˆå„ªåŒ– NPU ä½¿ç”¨ï¼‰"""
        print("[Map-Reduce] é–‹å§‹ä½¿ç”¨ Map-Reduce ç­–ç•¥ç”Ÿæˆå ±å‘Š...")
        
        # ä¼°ç®—ä¸Šä¸‹æ–‡å¤§å°
        context_size = self.map_reduce_service.estimate_context_size(conversation, citations)
        print(f"[Map-Reduce] ä¸Šä¸‹æ–‡å¤§å°åˆ†æ: {context_size}")
        
        # ä½¿ç”¨ Map-Reduce æœå‹™è™•ç†å¤§ä¸Šä¸‹æ–‡
        condensed_context = self.map_reduce_service.process_large_context(conversation, citations)
        
        # æ§‹å»ºæœ€çµ‚çš„è©³ç´°æç¤ºè©
        conversation_text = conversation.get_conversation_text()
        checklist = case.get_feedback_checklist()
        critical_actions = case.get_critical_actions()
        
        final_prompt = f"""
ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ OSCE è‡¨åºŠæ•™å¸«å’Œå¿ƒè‡Ÿç§‘å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šç”Ÿæˆä¸€ä»½è©³ç´°çš„è¨ºå¾Œåˆ†æå ±å‘Šã€‚

### å­¸ç”Ÿå•è¨ºè¡¨ç¾
{conversation_text}

### è©•ä¼°æ¨™æº–
**æª¢æŸ¥æ¸…å–®ï¼š**
{chr(10).join([f"- {item['point']} (é¡åˆ¥: {item['category']})" for item in checklist])}

**é—œéµè¡Œå‹•ï¼š**
{chr(10).join([f"- {action}" for action in critical_actions])}

### ç›¸é—œè‡¨åºŠæŒ‡å¼•æ‘˜è¦ (å·²æ¿ƒç¸®)
{condensed_context}

### ä½ çš„ä»»å‹™
è«‹ç”Ÿæˆä¸€ä»½å°ˆæ¥­ã€è©³ç´°çš„åˆ†æå ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

## 1. å•è¨ºè¡¨ç¾è©•ä¼°
- ç³»çµ±æ€§åˆ†æå­¸ç”Ÿçš„å•è¨ºæŠ€å·§
- æŒ‡å‡ºå„ªé»å’Œä¸è¶³ä¹‹è™•
- å¼•ç”¨å…·é«”çš„å°è©±å…§å®¹ä½œç‚ºä¾æ“š

## 2. è‡¨åºŠæ±ºç­–åˆ†æ
- è©•ä¼°å­¸ç”Ÿçš„è‡¨åºŠæ€ç¶­éç¨‹
- åˆ†ææ˜¯å¦è­˜åˆ¥å‡ºé—œéµç—‡ç‹€å’Œå±éšªå› å­
- è©•ä¼°æ±ºç­–çš„æ™‚æ•ˆæ€§å’Œæº–ç¢ºæ€§

## 3. çŸ¥è­˜æ‡‰ç”¨è©•ä¼°
- è©•ä¼°å­¸ç”Ÿå°æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹çš„ç†è§£
- åˆ†ææ˜¯å¦éµå¾ªæ¨™æº–åŒ–å•è¨ºç¨‹åº
- è©•ä¼°å°é—œéµæª¢æŸ¥çš„èªçŸ¥

## 4. æ”¹é€²å»ºè­°
- åŸºæ–¼è‡¨åºŠæŒ‡å¼•æ‘˜è¦ï¼Œçµ¦å‡ºå…·é«”å»ºè­°
- æä¾›å¯¦ç”¨çš„å­¸ç¿’è³‡æºå’Œç·´ç¿’æ–¹å‘
- å»ºè­°ä¸‹ä¸€æ­¥çš„å­¸ç¿’é‡é»

## 5. è©•åˆ†ç¸½çµ
- çµ¦å‡ºå„é …ç›®çš„å…·é«”è©•åˆ† (1-10åˆ†)
- æä¾›ç¸½é«”è©•åƒ¹å’Œç­‰ç´š
- å»ºè­°æ˜¯å¦éœ€è¦é¡å¤–ç·´ç¿’

### é‡è¦è¦æ±‚ï¼š
1. **å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«æ•´ä»½å ±å‘Šï¼Œçµ•å°ä¸èƒ½ä½¿ç”¨ç°¡é«”ä¸­æ–‡**
2. **ç¦æ­¢åœ¨å ±å‘Šä¸­åŒ…å«ä»»ä½•ç°½åæ¬„ä½ï¼Œå¦‚ï¼š[å­¸ç”Ÿå§“å]ã€[æ—¥æœŸ]ã€[è©•ä¼°è€…å§“å]ã€[è©•ä¼°è€…ç°½å]ç­‰**
3. **å ±å‘Šå…§å®¹æ‡‰ç›´æ¥é–‹å§‹ï¼Œä¸éœ€è¦ä»»ä½•è¡¨å–®æ¬„ä½æˆ–ç°½åå€åŸŸ**
4. èªæ°£å°ˆæ¥­ä½†å‹å–„ï¼Œé©åˆé†«å­¸ç”Ÿå­¸ç¿’ä½¿ç”¨
5. ç¢ºä¿æ‰€æœ‰é†«å­¸è¡“èªä½¿ç”¨æ­£ç¢ºçš„ç¹é«”ä¸­æ–‡
6. å ±å‘Šæ‡‰çµæ§‹æ¸…æ™°ï¼Œæ˜“æ–¼é–±è®€
7. ç›´æ¥æä¾›åˆ†æå…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•éœ€è¦å¡«å¯«çš„ç©ºç™½æ¬„ä½
"""
        
        # æ§‹å»ºæœ€çµ‚è¨Šæ¯
        from ..models.conversation import Message
        messages = [Message(role=MessageRole.SYSTEM, content=final_prompt)]
        
        try:
            print("[Map-Reduce] æ­£åœ¨ç”Ÿæˆæœ€çµ‚å ±å‘Šï¼ˆæ‡‰è©²åœ¨ NPU ä¸Šé‹è¡Œï¼‰...")
            # é€™å€‹æœ€çµ‚ä»»å‹™ç¾åœ¨æ‡‰è©²èƒ½åœ¨ NPU ä¸Šé‹è¡Œï¼Œå› ç‚ºä¸Šä¸‹æ–‡å·²ç¶“è¢«å¤§å¹…ç¸®æ¸›
            report_content = self.ai_service.chat(messages)
            print("[Map-Reduce] å ±å‘Šç”Ÿæˆå®Œæˆ")
            
            # æ·»åŠ  Map-Reduce è™•ç†çš„å…ƒæ•¸æ“š
            if isinstance(report_content, str):
                report_content += f"\n\n---\n*æ­¤å ±å‘Šä½¿ç”¨ Map-Reduce ç­–ç•¥ç”Ÿæˆï¼Œå„ªåŒ–äº† NPU ä½¿ç”¨æ•ˆç‡*"
            
            return report_content
            
        except Exception as e:
            print(f"[Map-Reduce] æœ€çµ‚å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸºæœ¬åˆ†æ + æ¿ƒç¸®å…§å®¹
            basic_analysis = self._generate_basic_analysis(conversation, case)
            return f"""
# è©³ç´°è¨ºå¾Œåˆ†æå ±å‘Š

{basic_analysis}

---

## è‡¨åºŠæŒ‡å¼•æ‘˜è¦

{condensed_context}

---

*è¨»ï¼šæ­¤ç‚ºå‚™ç”¨è©³ç´°å ±å‘Šï¼Œä½¿ç”¨ Map-Reduce ç­–ç•¥è™•ç†ã€‚AI æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚*
            """
    
    def _append_citation_suggestions(self, citations: List[Citation]) -> str:
        """åœ¨å ±å‘Šæœ«å°¾æ·»åŠ åŸºæ–¼å¼•è¨»çš„å»ºè­°"""
        suggestions = "\n\n## åŸºæ–¼è‡¨åºŠæŒ‡å¼•çš„å»ºè­°\n\n"
        
        for citation in citations:
            suggestions += f"**æ ¹æ“š [å¼•è¨» {citation.id}] çš„æŒ‡å¼•ï¼š**\n"
            
            content = citation.content
            if 'ECG' in content or 'å¿ƒé›»åœ–' in content:
                suggestions += "- ECG å¿ƒé›»åœ–æª¢æŸ¥æ‡‰åœ¨ 10 åˆ†é˜å…§å®Œæˆï¼Œé€™æ˜¯æ€¥æ€§èƒ¸ç—›è©•ä¼°çš„ç¬¬ä¸€å„ªå…ˆæª¢æŸ¥\n"
            if 'STEMI' in content:
                suggestions += "- ç–‘ä¼¼ STEMI æ™‚æ‡‰ç«‹å³å•Ÿå‹•å¿ƒå°ç®¡åœ˜éšŠï¼Œæ™‚é–“å°±æ˜¯å¿ƒè‚Œ\n"
            if 'OPQRST' in content:
                suggestions += "- å•è¨ºæ‡‰éµå¾ª OPQRST çµæ§‹ï¼šç™¼ä½œæ™‚é–“ã€èª˜ç™¼å› å­ã€ç–¼ç—›æ€§è³ªã€æ”¾å°„ä½ç½®ã€åš´é‡ç¨‹åº¦ã€æŒçºŒæ™‚é–“\n"
            
            suggestions += "\n"
        
        return suggestions
    
    def _generate_queries_from_feedback(self, feedback_content: str) -> List[str]:
        """åŸºæ–¼AIå›é¥‹å…§å®¹ç”Ÿæˆç›¸é—œçš„RAGæŸ¥è©¢"""
        queries = []
        content_lower = feedback_content.lower()
        
        # æ ¹æ“šå›é¥‹å…§å®¹ä¸­çš„é—œéµè©ç”ŸæˆæŸ¥è©¢
        if any(keyword in content_lower for keyword in ["å•è¨º", "ç—…å²", "osce", "è¦†è“‹ç‡"]):
            queries.append("OSCE å•è¨ºæŠ€å·§å’Œç—…å²è©¢å•æŒ‡å—")
            
        if any(keyword in content_lower for keyword in ["ecg", "å¿ƒé›»åœ–", "12å°ç¨‹", "é—œéµæ±ºç­–"]):
            queries.append("ECG å¿ƒé›»åœ–åœ¨èƒ¸ç—›è©•ä¼°ä¸­çš„é‡è¦æ€§")
            
        if any(keyword in content_lower for keyword in ["é‘‘åˆ¥", "è¨ºæ–·", "æª¢æŸ¥", "stemi"]):
            queries.append("STEMI å’Œä¸ç©©å®šå‹å¿ƒçµç—›çš„è¨ºæ–·æ¨™æº–")
            queries.append("æ€¥æ€§èƒ¸ç—›çš„é‘‘åˆ¥è¨ºæ–·å’Œæª¢æŸ¥é …ç›®")
            
        if any(keyword in content_lower for keyword in ["opqrst", "ç–¼ç—›", "æ€§è³ª", "ä½ç½®", "æ”¾å°„"]):
            queries.append("èƒ¸ç—›å•è¨ºçš„ OPQRST æŠ€å·§å’Œé‡é»")
            
        if any(keyword in content_lower for keyword in ["ç³»çµ±æ€§", "æµç¨‹", "é †åº"]):
            queries.append("æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹å’Œæª¢æŸ¥é †åº")
            
        if any(keyword in content_lower for keyword in ["æ”¹é€²", "å»ºè­°", "ç·´ç¿’"]):
            queries.append("è‡¨åºŠè¨ºæ–·æŠ€å·§å’Œæœ€ä½³å¯¦è¸")
            
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šé—œéµè©ï¼Œä½¿ç”¨é€šç”¨æŸ¥è©¢
        if not queries:
            queries = [
                "æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹å’Œæª¢æŸ¥é †åº",
                "ECG å¿ƒé›»åœ–åœ¨èƒ¸ç—›è©•ä¼°ä¸­çš„é‡è¦æ€§"
            ]
            
        return queries[:3]  # è¿”å›æœ€å¤š3å€‹æŸ¥è©¢
    
    def _search_multiple_queries(self, queries: List[str], k: int = 2) -> str:
        """åŸ·è¡Œå¤šå€‹æŸ¥è©¢ä¸¦åˆä½µçµæœ"""
        all_results = []
        
        for i, query in enumerate(queries, 1):
            try:
                result = self.rag_service.search(query, k=k)
                if result and "RAG ç³»çµ±æœªåˆå§‹åŒ–" not in result and "æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™" not in result:
                    # æ·»åŠ æŸ¥è©¢æ¨™è­˜
                    formatted_result = f"ğŸ“š **{query}**\n\n{result}"
                    all_results.append(formatted_result)
            except Exception as e:
                print(f"æŸ¥è©¢å¤±æ•—: {query} - {e}")
                continue
                
        # åˆä½µçµæœï¼Œé¿å…é‡è¤‡
        if all_results:
            return "\n\n---\n\n".join(all_results[:2])  # æœ€å¤šè¿”å›2å€‹çµæœ
        else:
            return ""
    
    def _save_report_to_file(self, report: Report) -> Optional[str]:
        """å°‡å ±å‘Šå„²å­˜åˆ°æœ¬åœ° md æª”æ¡ˆ"""
        try:
            # ç”Ÿæˆæª”æ¡ˆåç¨±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = generate_report_filename(
                case_id=report.case_id,
                report_type=report.report_type.value,
                timestamp=timestamp
            )
            
            # æ§‹å»ºå®Œæ•´çš„å ±å‘Šå…§å®¹ï¼ˆåŒ…å« metadataï¼‰
            full_report_content = self._format_report_for_file(report)
            
            # å„²å­˜åˆ°æª”æ¡ˆ
            file_path = save_report_to_file(
                report_content=full_report_content,
                filename=filename,
                directory_path=self.settings.report_history_dir
            )
            
            if file_path:
                print(f"å ±å‘Šå·²å„²å­˜è‡³: {file_path}")
                return str(file_path)
            else:
                print("å ±å‘Šå„²å­˜å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"å„²å­˜å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def _format_report_for_file(self, report: Report) -> str:
        """æ ¼å¼åŒ–å ±å‘Šå…§å®¹ç”¨æ–¼æª”æ¡ˆå„²å­˜"""
        # å ±å‘Šæ¨™é¡Œ
        report_title = "å³æ™‚å›é¥‹å ±å‘Š" if report.report_type == ReportType.FEEDBACK else "è©³ç´°åˆ†æå ±å‘Š"
        
        # åŸºæœ¬è³‡è¨Š
        metadata_section = f"""# {report_title}

## å ±å‘Šè³‡è¨Š
- **æ¡ˆä¾‹ ID**: {report.case_id}
- **å ±å‘Šé¡å‹**: {report.report_type.value}
- **ç”Ÿæˆæ™‚é–“**: {report.metadata.get('generated_at', 'N/A')}
- **å•è¨ºè¦†è“‹ç‡**: {report.coverage}%
- **å°è©±é•·åº¦**: {report.metadata.get('conversation_length', 'N/A')} æ¢è¨Šæ¯

"""
        
        # å¦‚æœæœ‰å¼•è¨»ï¼Œæ·»åŠ å¼•è¨»è³‡è¨Š
        citations_section = ""
        if report.citations:
            citations_section = f"""
## å¼•è¨»è³‡è¨Š
- **å¼•è¨»æ•¸é‡**: {len(report.citations)}
- **RAG æŸ¥è©¢**: {', '.join(report.rag_queries) if report.rag_queries else 'N/A'}

"""
        
        # å ±å‘Šå…§å®¹
        content_section = f"""
## å ±å‘Šå…§å®¹

{report.content}
"""
        
        # å¦‚æœæœ‰å¼•è¨»ï¼Œæ·»åŠ è©³ç´°å¼•è¨»
        detailed_citations = ""
        if report.citations:
            detailed_citations = f"""

## è©³ç´°å¼•è¨»

"""
            for i, citation in enumerate(report.citations, 1):
                score_info = ""
                if hasattr(citation, 'score') and citation.score is not None:
                    score_info = f"- **ç›¸é—œæ€§åˆ†æ•¸**: {citation.score:.3f}\n"
                
                detailed_citations += f"""### å¼•è¨» {citation.id}
- **æŸ¥è©¢**: {citation.query}
- **ä¾†æº**: {citation.source}
{score_info}- **å…§å®¹**: 
```
{citation.content}
```

---
"""
        
        # çµ„åˆå®Œæ•´å…§å®¹
        full_content = (
            metadata_section +
            citations_section +
            content_section +
            detailed_citations +
            f"""

---
*æ­¤å ±å‘Šç”± ClinicSim-AI ç³»çµ±è‡ªå‹•ç”Ÿæˆæ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        )
        
        return full_content
    
    def _generate_enhanced_analysis(self, conversation: Conversation, case: Case, scoring_result) -> str:
        """ç”Ÿæˆå¢å¼·åˆ†æå ±å‘Šï¼ˆåŒ…å«çµæ§‹åŒ–è©•åˆ†ï¼‰"""
        # åŸºæœ¬è¦†è“‹ç‡åˆ†æï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        checklist = case.get_feedback_checklist()
        conversation_text = conversation.get_conversation_text().lower()
        
        report_items = []
        covered_count = 0
        partial_count = 0
        
        for item in checklist:
            keywords = item.get('keywords', [])
            matched_keywords = [kw for kw in keywords if kw.lower() in conversation_text]
            
            if len(matched_keywords) >= 2:
                report_items.append(f"- âœ… {item['point']}ï¼šå­¸ç”Ÿé€éæå•ã€Œ{matched_keywords[0]}ã€ç­‰æˆåŠŸå•è¨º")
                covered_count += 1
            elif len(matched_keywords) == 1:
                report_items.append(f"- âš ï¸ {item['point']}ï¼šå­¸ç”Ÿæœ‰ç›¸é—œæå•ã€Œ{matched_keywords[0]}ã€ï¼Œä½†å¯æ›´æ·±å…¥")
                partial_count += 1
            else:
                report_items.append(f"- âŒ {item['point']}ï¼šå­¸ç”Ÿæœªè©¢å•æ­¤é …ç›®")
        
        # çµæ§‹åŒ–è©•åˆ†åˆ†æ
        scoring_analysis = self._format_scoring_analysis(scoring_result)
        
        coverage_percentage = conversation.coverage
        
        return f"""### è¨ºå¾Œåˆ†æå ±å‘Š

**ç¸½é«”è©•åˆ†ï¼š{scoring_result.percentage:.1f}% ({scoring_result.grade})**
**å•è¨ºè¦†è“‹ç‡ï¼š{coverage_percentage}% ({covered_count + partial_count}/{len(checklist)})**

{scoring_analysis}

**è©³ç´°è©•ä¼°ï¼š**
{chr(10).join(report_items)}

### ç¸½çµèˆ‡å»ºè­°

**å„ªé»ï¼š**
- ç¸½é«”è©•åˆ†é” {scoring_result.percentage:.1f}%ï¼Œç­‰ç´šï¼š{scoring_result.grade}
- å•è¨ºè¦†è“‹ç‡é” {coverage_percentage}%ï¼Œå…±è¦†è“‹ {covered_count + partial_count} å€‹é …ç›®
- å­¸ç”Ÿå±•ç¾äº†åŸºæœ¬çš„å•è¨ºæŠ€å·§

**æ”¹é€²å»ºè­°ï¼š**
1. **ç³»çµ±æ€§å•è¨º**ï¼šå»ºè­°æŒ‰ç…§ OPQRST çµæ§‹é€²è¡Œå•è¨º
2. **æ·±å…¥æ¢ç´¢**ï¼šå°æ–¼å·²è§¸åŠçš„ä¸»é¡Œï¼Œå¯ä»¥é€²ä¸€æ­¥æ·±å…¥è©¢å•
3. **é—œéµæ±ºç­–**ï¼šåŠ å¼·è‡¨åºŠæ±ºç­–èƒ½åŠ›ï¼ŒåŠæ™‚æå‡ºé—œéµæª¢æŸ¥
4. **å®Œæ•´æ€§**ï¼šæ³¨æ„å•è¨ºçš„å…¨é¢æ€§ï¼Œé¿å…éºæ¼é‡è¦é …ç›®

**å…·é«”å»ºè­°ï¼š**
- å¤šç·´ç¿’æ¨™æº–åŒ–å•è¨ºæµç¨‹
- åŠ å¼·å°é—œéµç—‡ç‹€çš„è­˜åˆ¥èƒ½åŠ›
- æå‡è‡¨åºŠæ±ºç­–çš„æ™‚æ•ˆæ€§

*è¨»ï¼šæ­¤ç‚ºå³æ™‚åˆ†æå ±å‘Šï¼Œè©³ç´°å ±å‘Šè«‹é»æ“Šã€Œç”Ÿæˆå®Œæ•´å ±å‘Šã€æŒ‰éˆ•ã€‚*"""
    
    def _format_scoring_analysis(self, scoring_result) -> str:
        """æ ¼å¼åŒ–è©•åˆ†åˆ†æ - æ”¹é€²çš„é¡¯ç¤ºé‚è¼¯"""
        analysis_parts = []
        
        # å„é¡åˆ¥è©•åˆ†
        for section in scoring_result.section_scores:
            section_percentage = (section.achieved_score / section.max_score * 100) if section.max_score > 0 else 0
            analysis_parts.append(f"**{section.title}**: {section_percentage:.1f}% ({section.achieved_score:.1f}/{section.max_score})")
            
            # é¡¯ç¤ºæ‰€æœ‰è©•åˆ†é …ç›®çš„è©³ç´°ç‹€æ…‹
            for criterion in section.criteria_scores:
                # æ”¹é€²çš„é¡¯ç¤ºé‚è¼¯ï¼šæ ¹æ“šåˆ†æ•¸æ¯”ä¾‹æ±ºå®šé¡¯ç¤ºç‹€æ…‹
                score_ratio = criterion.achieved_score / criterion.max_score if criterion.max_score > 0 else 0
                
                if score_ratio >= 0.8:
                    status_icon = "âœ…"  # 80%ä»¥ä¸Šç‚ºç¶ è‰²å‹¾å‹¾
                    status_text = "å„ªç§€"
                elif score_ratio >= 0.5:
                    status_icon = "âš ï¸"  # 50-80%ç‚ºé»ƒè‰²è­¦å‘Š
                    status_text = "è‰¯å¥½"
                elif score_ratio > 0:
                    status_icon = "ğŸŸ¡"  # 1-50%ç‚ºé»ƒè‰²åœ“é»
                    status_text = "éƒ¨åˆ†å®Œæˆ"
                else:
                    status_icon = "âŒ"  # 0åˆ†ç‚ºç´…è‰²å‰å‰
                    status_text = "æœªå®Œæˆ"
                
                analysis_parts.append(f"  - {status_icon} {criterion.description} ({status_text})")
            
            # é¡¯ç¤ºæ‡²ç½°é …ç›®
            penalties = [p for p in section.penalties if p.achieved_score > 0]
            if penalties:
                analysis_parts.append(f"  - æ‰£åˆ†é …ç›®: {', '.join([p.description for p in penalties])}")
        
        return "\n".join(analysis_parts)
    
    def sync_existing_report_to_notion(self, file_path: str, page_title: str = None) -> Optional[str]:
        """
        å°‡ç¾æœ‰çš„å ±å‘Šæª”æ¡ˆåŒæ­¥åˆ° Notion
        
        Args:
            file_path: å ±å‘Šæª”æ¡ˆè·¯å¾‘
            page_title: Notion é é¢æ¨™é¡Œï¼ˆå¯é¸ï¼‰
            
        Returns:
            å‰µå»ºçš„é é¢ IDï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        if not self.notion_service.is_available():
            print("âŒ Notion æœå‹™ä¸å¯ç”¨")
            return None
        
        try:
            # å¦‚æœæ²’æœ‰æä¾›æ¨™é¡Œï¼Œå¾æª”æ¡ˆåç”Ÿæˆ
            if not page_title:
                file_path_obj = Path(file_path)
                page_title = f"å­¸ç¿’å ±å‘Š - {file_path_obj.stem}"
            
            # ä½¿ç”¨ NotionService åŒæ­¥å ±å‘Š
            page_id = self.notion_service.sync_report_to_notion(
                report_file_path=file_path,
                page_title=page_title
            )
            
            if page_id:
                print(f"âœ… æˆåŠŸåŒæ­¥å ±å‘Šåˆ° Notion: {page_title}")
                return page_id
            else:
                print(f"âŒ åŒæ­¥å ±å‘Šåˆ° Notion å¤±æ•—: {page_title}")
                return None
                
        except Exception as e:
            print(f"âŒ åŒæ­¥ç¾æœ‰å ±å‘Šåˆ° Notion æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
