"""
å ±å‘Šç”Ÿæˆæœå‹™
"""

import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

from ..models.conversation import Conversation, MessageRole
from ..models.case import Case
from ..models.report import Report, ReportType, Citation
from ..services.ai_service import get_ai_service
from ..services.rag_service import RAGService
from ..services.case_service import CaseService
from ..services.scoring_service import ScoringService
from ..config.settings import get_settings
from ..utils.file_utils import save_report_to_file, generate_report_filename


class ReportService:
    """å ±å‘Šç”Ÿæˆæœå‹™"""
    
    def __init__(self, settings=None, case_service=None, ai_service=None, rag_service=None, scoring_service=None):
        self.settings = settings or get_settings()
        self.case_service = case_service or CaseService(self.settings)
        self.ai_service = ai_service or get_ai_service(self.settings)
        self.rag_service = rag_service or RAGService(self.settings)
        self.scoring_service = scoring_service or ScoringService(self.settings)
    
    def generate_feedback_report(self, conversation: Conversation) -> Report:
        """ç”Ÿæˆå³æ™‚å›žé¥‹å ±å‘Š"""
        case = self.case_service.get_case(conversation.case_id)
        if not case:
            raise ValueError(f"Case not found: {conversation.case_id}")
        
        # ç¢ºä¿è¦†è“‹çŽ‡æ˜¯æœ€æ–°çš„
        from ..services.conversation_service import ConversationService
        conversation_service = ConversationService(self.settings)
        conversation_service._update_conversation_metrics(conversation, case)
        
        # ä½¿ç”¨æ–°çš„çµæ§‹åŒ–è©•åˆ†ç³»çµ±
        scoring_result = self.scoring_service.score_conversation(conversation)
        
        # ç”ŸæˆåŸºæœ¬åˆ†æžå ±å‘Šï¼ˆåŒ…å«æ–°è©•åˆ†ï¼‰
        report_content = self._generate_enhanced_analysis(conversation, case, scoring_result)
        
        # å¦‚æžœæœ‰ RAG æœå‹™ï¼ŒåŸºæ–¼å›žé¥‹å…§å®¹æ·»åŠ ç›¸é—œæŒ‡å¼•
        if self.rag_service.is_available():
            # åŸºæ–¼å·²ç”Ÿæˆçš„å›žé¥‹å…§å®¹ç”Ÿæˆç›¸é—œæŸ¥è©¢
            rag_queries = self._generate_queries_from_feedback(report_content)
            
            # ä½¿ç”¨æŸ¥è©¢ç²å–æœ€ç›¸é—œçš„æŒ‡å¼•
            if rag_queries:
                rag_context = self._search_multiple_queries(rag_queries, k=2)
                if rag_context and "RAG ç³»çµ±æœªåˆå§‹åŒ–" not in rag_context:
                    report_content += f"\n\n### ç›¸é—œè‡¨åºŠæŒ‡å¼•\n{rag_context}"
        
        report = Report(
            report_type=ReportType.FEEDBACK,
            content=report_content,
            case_id=conversation.case_id,
            coverage=conversation.coverage,
            metadata={
                "generated_at": datetime.now().isoformat(),
                "conversation_length": len(conversation.messages)
            }
        )
        
        conversation.mark_report_generated()
        
        # å„²å­˜å ±å‘Šåˆ°æª”æ¡ˆ
        self._save_report_to_file(report)
        
        return report
    
    def generate_detailed_report(self, conversation: Conversation) -> Report:
        """ç”Ÿæˆè©³ç´°åˆ†æžå ±å‘Šï¼ˆä½¿ç”¨ LLM + RAGï¼‰"""
        case = self.case_service.get_case(conversation.case_id)
        if not case:
            raise ValueError(f"Case not found: {conversation.case_id}")
        
        # å…ˆç”Ÿæˆåˆæ­¥åˆ†æžå ±å‘Š
        initial_feedback = self._generate_basic_analysis(conversation, case)
        
        # åŸºæ–¼åˆæ­¥å›žé¥‹å…§å®¹ç”Ÿæˆæ›´ç²¾æº–çš„ RAG æŸ¥è©¢
        rag_queries = self._generate_queries_from_feedback(initial_feedback)
        
        citations = []
        if self.rag_service.is_available():
            # ä½¿ç”¨æ–°çš„ search_with_citations æ–¹æ³•ç”Ÿæˆå¸¶æœ‰å®Œæ•´ä¾†æºè³‡è¨Šçš„å¼•è¨»
            citations = self.rag_service.search_with_citations(rag_queries, k=2)
        
        # ç”Ÿæˆè©³ç´°å ±å‘Šå…§å®¹
        report_content = self._generate_detailed_analysis_with_llm(
            conversation, case, citations
        )
        
        report = Report(
            report_type=ReportType.DETAILED,
            content=report_content,
            case_id=conversation.case_id,
            citations=citations,
            rag_queries=rag_queries,
            coverage=conversation.coverage,
            metadata={
                "generated_at": datetime.now().isoformat(),
                "conversation_length": len(conversation.messages),
                "rag_available": self.rag_service.is_available(),
                "citations_count": len(citations)
            }
        )
        
        conversation.mark_detailed_report_generated()
        
        # å„²å­˜å ±å‘Šåˆ°æª”æ¡ˆ
        file_path = self._save_report_to_file(report)
        
        # å°‡æª”æ¡ˆè·¯å¾‘æ·»åŠ åˆ°å ±å‘Šå…ƒè³‡æ–™
        if file_path:
            report.metadata['file_path'] = file_path
            report.metadata['filename'] = Path(file_path).name
        
        return report
    
    def _generate_basic_analysis(self, conversation: Conversation, case: Case) -> str:
        """ç”ŸæˆåŸºæœ¬åˆ†æžå ±å‘Šï¼ˆä¸ä½¿ç”¨ LLMï¼‰"""
        checklist = case.get_feedback_checklist()
        critical_actions = case.get_critical_actions()
        user_messages = conversation.get_user_messages()
        
        # åˆ†æžè¦†è“‹çŽ‡
        conversation_text = conversation.get_conversation_text().lower()
        
        report_items = []
        covered_count = 0
        partial_count = 0
        
        for item in checklist:
            keywords = item.get('keywords', [])
            matched_keywords = [kw for kw in keywords if kw.lower() in conversation_text]
            
            if len(matched_keywords) >= 2:
                report_items.append(f"- âœ… {item['point']}ï¼šå­¸ç”Ÿé€éŽæå•ã€Œ{matched_keywords[0]}ã€ç­‰æˆåŠŸå•è¨º")
                covered_count += 1
            elif len(matched_keywords) == 1:
                report_items.append(f"- âš ï¸ {item['point']}ï¼šå­¸ç”Ÿæœ‰ç›¸é—œæå•ã€Œ{matched_keywords[0]}ã€ï¼Œä½†å¯æ›´æ·±å…¥")
                partial_count += 1
            else:
                report_items.append(f"- âŒ {item['point']}ï¼šå­¸ç”Ÿæœªè©¢å•æ­¤é …ç›®")
        
        # åˆ†æžé—œéµè¡Œå‹•
        critical_analysis = []
        for action in critical_actions:
            # é‡å°ä¸åŒçš„é—œéµè¡Œå‹•ä½¿ç”¨ä¸åŒçš„é—œéµå­—åŒ¹é…
            if "ECG" in action or "å¿ƒé›»åœ–" in action:
                # ECGç›¸é—œè¡Œå‹•çš„é—œéµå­—
                ecg_keywords = ["å¿ƒé›»åœ–", "ECG", "12å°Žç¨‹", "12å°Ž", "ç«‹åˆ»", "é¦¬ä¸Š", "ç«‹å³", "10åˆ†", "ååˆ†"]
                if any(keyword in conversation_text for keyword in ecg_keywords):
                    critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
                else:
                    critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
            elif "Troponin" in action or "å¿ƒè‚Œéˆ£è›‹ç™½" in action:
                # Troponinç›¸é—œè¡Œå‹•çš„é—œéµå­—
                troponin_keywords = ["troponin", "å¿ƒè‚Œéˆ£è›‹ç™½", "å¿ƒè‚Œé…µç´ ", "æŠ½è¡€", "æª¢é©—", "è¡€æ¶²"]
                if any(keyword in conversation_text for keyword in troponin_keywords):
                    critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
                else:
                    critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
            else:
                # å…¶ä»–é—œéµè¡Œå‹•çš„é€šç”¨åŒ¹é…
                if any(keyword in conversation_text for keyword in ["å¿ƒé›»åœ–", "ECG", "12å°Žç¨‹", "ç«‹åˆ»", "é¦¬ä¸Š", "10åˆ†"]):
                    critical_analysis.append(f"- âœ… é—œéµæ±ºç­–ï¼šå­¸ç”ŸæåŠäº†ã€Œ{action}ã€")
                else:
                    critical_analysis.append(f"- âŒ é—œéµæ±ºç­–ï¼šå­¸ç”ŸæœªæåŠã€Œ{action}ã€")
        
        coverage_percentage = conversation.coverage
        
        return f"""### è¨ºå¾Œåˆ†æžå ±å‘Š

**å•è¨ºè¦†è“‹çŽ‡ï¼š{coverage_percentage}% ({covered_count + partial_count}/{len(checklist)})**
**å®Œæ•´é …ç›®ï¼š{covered_count} | éƒ¨åˆ†é …ç›®ï¼š{partial_count} | æœªè¦†è“‹ï¼š{len(checklist) - covered_count - partial_count}**

**è©³ç´°è©•ä¼°ï¼š**
{chr(10).join(report_items)}

**é—œéµè¡Œå‹•è©•ä¼°ï¼š**
{chr(10).join(critical_analysis)}

### ç¸½çµèˆ‡å»ºè­°

**å„ªé»žï¼š**
- å•è¨ºè¦†è“‹çŽ‡é” {coverage_percentage}%ï¼Œå…±è¦†è“‹ {covered_count + partial_count} å€‹é …ç›®
- å­¸ç”Ÿå±•ç¾äº†åŸºæœ¬çš„å•è¨ºæŠ€å·§
- èƒ½å¤ èˆ‡ç—…äººå»ºç«‹è‰¯å¥½çš„æºé€š

**æ”¹é€²å»ºè­°ï¼š**
1. **ç³»çµ±æ€§å•è¨º**ï¼šå»ºè­°æŒ‰ç…§ OPQRST çµæ§‹é€²è¡Œå•è¨º
2. **æ·±å…¥æŽ¢ç´¢**ï¼šå°æ–¼å·²è§¸åŠçš„ä¸»é¡Œï¼Œå¯ä»¥é€²ä¸€æ­¥æ·±å…¥è©¢å•
3. **é—œéµæ±ºç­–**ï¼šåŠ å¼·è‡¨åºŠæ±ºç­–èƒ½åŠ›ï¼ŒåŠæ™‚æå‡ºé—œéµæª¢æŸ¥
4. **å®Œæ•´æ€§**ï¼šæ³¨æ„å•è¨ºçš„å…¨é¢æ€§ï¼Œé¿å…éºæ¼é‡è¦é …ç›®

**å…·é«”å»ºè­°ï¼š**
- å¤šç·´ç¿’æ¨™æº–åŒ–å•è¨ºæµç¨‹
- åŠ å¼·å°é—œéµç—‡ç‹€çš„è­˜åˆ¥èƒ½åŠ›
- æå‡è‡¨åºŠæ±ºç­–çš„æ™‚æ•ˆæ€§

*è¨»ï¼šæ­¤ç‚ºå³æ™‚åˆ†æžå ±å‘Šï¼Œè©³ç´°å ±å‘Šè«‹é»žæ“Šã€Œç”Ÿæˆå®Œæ•´å ±å‘Šã€æŒ‰éˆ•ã€‚*"""
    
    def _generate_detailed_analysis_with_llm(self, conversation: Conversation, case: Case, citations: List[Citation]) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆè©³ç´°åˆ†æžå ±å‘Š"""
        # æ§‹å»º RAG ä¸Šä¸‹æ–‡
        rag_context = "\n\n".join([
            f"### é—œæ–¼ {citation.query} [å¼•è¨» {citation.id}]\n{citation.content}"
            for citation in citations
        ]) if citations else "æœªæ‰¾åˆ°ç›¸é—œè‡¨åºŠæŒ‡å¼•"
        
        # æ§‹å»ºè©³ç´°æç¤ºè©ž
        detailed_prompt = f"""
        ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ OSCE è‡¨åºŠæ•™å¸«å’Œå¿ƒè‡Ÿç§‘å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šç”Ÿæˆä¸€ä»½è©³ç´°çš„è¨ºå¾Œåˆ†æžå ±å‘Šã€‚

        ### å­¸ç”Ÿå•è¨ºè¡¨ç¾
        {conversation.get_conversation_text()}

        ### è©•ä¼°æ¨™æº–
        **æª¢æŸ¥æ¸…å–®ï¼š**
        {chr(10).join([f"- {item['point']} (é¡žåˆ¥: {item['category']})" for item in case.get_feedback_checklist()])}

        **é—œéµè¡Œå‹•ï¼š**
        {chr(10).join([f"- {action}" for action in case.get_critical_actions()])}

        ### ç›¸é—œè‡¨åºŠæŒ‡å¼• (RAG ç³»çµ±æä¾›)
        {rag_context}

        ### ä½ çš„ä»»å‹™
        è«‹ç”Ÿæˆä¸€ä»½å°ˆæ¥­ã€è©³ç´°çš„åˆ†æžå ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

        ## 1. å•è¨ºè¡¨ç¾è©•ä¼°
        - ç³»çµ±æ€§åˆ†æžå­¸ç”Ÿçš„å•è¨ºæŠ€å·§
        - æŒ‡å‡ºå„ªé»žå’Œä¸è¶³ä¹‹è™•
        - å¼•ç”¨å…·é«”çš„å°è©±å…§å®¹ä½œç‚ºä¾æ“š

        ## 2. è‡¨åºŠæ±ºç­–åˆ†æž
        - è©•ä¼°å­¸ç”Ÿçš„è‡¨åºŠæ€ç¶­éŽç¨‹
        - åˆ†æžæ˜¯å¦è­˜åˆ¥å‡ºé—œéµç—‡ç‹€å’Œå±éšªå› å­
        - è©•ä¼°æ±ºç­–çš„æ™‚æ•ˆæ€§å’Œæº–ç¢ºæ€§

        ## 3. çŸ¥è­˜æ‡‰ç”¨è©•ä¼°
        - è©•ä¼°å­¸ç”Ÿå°æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹çš„ç†è§£
        - åˆ†æžæ˜¯å¦éµå¾ªæ¨™æº–åŒ–å•è¨ºç¨‹åº
        - è©•ä¼°å°é—œéµæª¢æŸ¥çš„èªçŸ¥

        ## 4. æ”¹é€²å»ºè­°
        - åŸºæ–¼ RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•ï¼Œçµ¦å‡ºå…·é«”å»ºè­°
        - æä¾›å¯¦ç”¨çš„å­¸ç¿’è³‡æºå’Œç·´ç¿’æ–¹å‘
        - å»ºè­°ä¸‹ä¸€æ­¥çš„å­¸ç¿’é‡é»ž

        ## 5. è©•åˆ†ç¸½çµ
        - çµ¦å‡ºå„é …ç›®çš„å…·é«”è©•åˆ† (1-10åˆ†)
        - æä¾›ç¸½é«”è©•åƒ¹å’Œç­‰ç´š
        - å»ºè­°æ˜¯å¦éœ€è¦é¡å¤–ç·´ç¿’

        ### é‡è¦è¦æ±‚ï¼š
        1. å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«æ•´ä»½å ±å‘Š
        2. åœ¨å¼•ç”¨è‡¨åºŠæŒ‡å¼•æ™‚ï¼Œå¿…é ˆä½¿ç”¨ [å¼•è¨» X] çš„æ ¼å¼æ¨™è¨˜ï¼Œä¾‹å¦‚ [å¼•è¨» 1]ã€[å¼•è¨» 2] ç­‰
        3. æ¯å€‹å»ºè­°éƒ½æ‡‰è©²å¼•ç”¨ç›¸æ‡‰çš„è‡¨åºŠæŒ‡å¼•ï¼Œæ ¼å¼ç‚ºï¼šæ ¹æ“š [å¼•è¨» X] çš„æŒ‡å¼•...
        4. èªžæ°£å°ˆæ¥­ä½†å‹å–„ï¼Œé©åˆé†«å­¸ç”Ÿå­¸ç¿’ä½¿ç”¨
        5. ç¢ºä¿æ‰€æœ‰é†«å­¸è¡“èªžä½¿ç”¨æ­£ç¢ºçš„ç¹é«”ä¸­æ–‡
        """
        
        # æ§‹å»ºè¨Šæ¯
        from ..models.conversation import Message
        messages = [Message(role=MessageRole.SYSTEM, content=detailed_prompt)]
        
        try:
            # ä½¿ç”¨ AI æœå‹™ç”Ÿæˆå ±å‘Š
            report_content = self.ai_service.chat(messages)
            
            # å¦‚æžœ AI æ²’æœ‰ç”Ÿæˆå¼•è¨»æ¨™è¨˜ï¼Œæ‰‹å‹•æ·»åŠ 
            if not re.search(r'\[å¼•è¨» \d+\]', report_content) and citations:
                report_content += self._append_citation_suggestions(citations)
            
            return report_content
            
        except Exception as e:
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸºæœ¬åˆ†æž + RAG å…§å®¹
            basic_analysis = self._generate_basic_analysis(conversation, case)
            return f"""
# è©³ç´°è¨ºå¾Œåˆ†æžå ±å‘Š

{basic_analysis}

---

## RAG æä¾›çš„è‡¨åºŠæŒ‡å¼•

{rag_context}

---

*è¨»ï¼šæ­¤ç‚ºå‚™ç”¨è©³ç´°å ±å‘Šï¼ŒåŒ…å« RAG æœå°‹çš„è‡¨åºŠæŒ‡å¼•å…§å®¹ã€‚AI æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚*
            """
    
    def _append_citation_suggestions(self, citations: List[Citation]) -> str:
        """åœ¨å ±å‘Šæœ«å°¾æ·»åŠ åŸºæ–¼å¼•è¨»çš„å»ºè­°"""
        suggestions = "\n\n## åŸºæ–¼è‡¨åºŠæŒ‡å¼•çš„å»ºè­°\n\n"
        
        for citation in citations:
            suggestions += f"**æ ¹æ“š [å¼•è¨» {citation.id}] çš„æŒ‡å¼•ï¼š**\n"
            
            content = citation.content
            if 'ECG' in content or 'å¿ƒé›»åœ–' in content:
                suggestions += "- ECG å¿ƒé›»åœ–æª¢æŸ¥æ‡‰åœ¨ 10 åˆ†é˜å…§å®Œæˆï¼Œé€™æ˜¯æ€¥æ€§èƒ¸ç—›è©•ä¼°çš„ç¬¬ä¸€å„ªå…ˆæª¢æŸ¥\n"
            if 'STEMI' in content:
                suggestions += "- ç–‘ä¼¼ STEMI æ™‚æ‡‰ç«‹å³å•Ÿå‹•å¿ƒå°Žç®¡åœ˜éšŠï¼Œæ™‚é–“å°±æ˜¯å¿ƒè‚Œ\n"
            if 'OPQRST' in content:
                suggestions += "- å•è¨ºæ‡‰éµå¾ª OPQRST çµæ§‹ï¼šç™¼ä½œæ™‚é–“ã€èª˜ç™¼å› å­ã€ç–¼ç—›æ€§è³ªã€æ”¾å°„ä½ç½®ã€åš´é‡ç¨‹åº¦ã€æŒçºŒæ™‚é–“\n"
            
            suggestions += "\n"
        
        return suggestions
    
    def _generate_queries_from_feedback(self, feedback_content: str) -> List[str]:
        """åŸºæ–¼AIå›žé¥‹å…§å®¹ç”Ÿæˆç›¸é—œçš„RAGæŸ¥è©¢"""
        queries = []
        content_lower = feedback_content.lower()
        
        # æ ¹æ“šå›žé¥‹å…§å®¹ä¸­çš„é—œéµè©žç”ŸæˆæŸ¥è©¢
        if any(keyword in content_lower for keyword in ["å•è¨º", "ç—…å²", "osce", "è¦†è“‹çŽ‡"]):
            queries.append("OSCE å•è¨ºæŠ€å·§å’Œç—…å²è©¢å•æŒ‡å—")
            
        if any(keyword in content_lower for keyword in ["ecg", "å¿ƒé›»åœ–", "12å°Žç¨‹", "é—œéµæ±ºç­–"]):
            queries.append("ECG å¿ƒé›»åœ–åœ¨èƒ¸ç—›è©•ä¼°ä¸­çš„é‡è¦æ€§")
            
        if any(keyword in content_lower for keyword in ["é‘‘åˆ¥", "è¨ºæ–·", "æª¢æŸ¥", "stemi"]):
            queries.append("STEMI å’Œä¸ç©©å®šåž‹å¿ƒçµžç—›çš„è¨ºæ–·æ¨™æº–")
            queries.append("æ€¥æ€§èƒ¸ç—›çš„é‘‘åˆ¥è¨ºæ–·å’Œæª¢æŸ¥é …ç›®")
            
        if any(keyword in content_lower for keyword in ["opqrst", "ç–¼ç—›", "æ€§è³ª", "ä½ç½®", "æ”¾å°„"]):
            queries.append("èƒ¸ç—›å•è¨ºçš„ OPQRST æŠ€å·§å’Œé‡é»ž")
            
        if any(keyword in content_lower for keyword in ["ç³»çµ±æ€§", "æµç¨‹", "é †åº"]):
            queries.append("æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹å’Œæª¢æŸ¥é †åº")
            
        if any(keyword in content_lower for keyword in ["æ”¹é€²", "å»ºè­°", "ç·´ç¿’"]):
            queries.append("è‡¨åºŠè¨ºæ–·æŠ€å·§å’Œæœ€ä½³å¯¦è¸")
            
        # å¦‚æžœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šé—œéµè©žï¼Œä½¿ç”¨é€šç”¨æŸ¥è©¢
        if not queries:
            queries = [
                "æ€¥æ€§èƒ¸ç—›è¨ºæ–·æµç¨‹å’Œæª¢æŸ¥é †åº",
                "ECG å¿ƒé›»åœ–åœ¨èƒ¸ç—›è©•ä¼°ä¸­çš„é‡è¦æ€§"
            ]
            
        return queries[:3]  # è¿”å›žæœ€å¤š3å€‹æŸ¥è©¢
    
    def _search_multiple_queries(self, queries: List[str], k: int = 2) -> str:
        """åŸ·è¡Œå¤šå€‹æŸ¥è©¢ä¸¦åˆä½µçµæžœ"""
        all_results = []
        
        for i, query in enumerate(queries, 1):
            try:
                result = self.rag_service.search(query, k=k)
                if result and "RAG ç³»çµ±æœªåˆå§‹åŒ–" not in result and "æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™" not in result:
                    # æ·»åŠ æŸ¥è©¢æ¨™è­˜
                    formatted_result = f"ðŸ“š **{query}**\n\n{result}"
                    all_results.append(formatted_result)
            except Exception as e:
                print(f"æŸ¥è©¢å¤±æ•—: {query} - {e}")
                continue
                
        # åˆä½µçµæžœï¼Œé¿å…é‡è¤‡
        if all_results:
            return "\n\n---\n\n".join(all_results[:2])  # æœ€å¤šè¿”å›ž2å€‹çµæžœ
        else:
            return ""
    
    def _save_report_to_file(self, report: Report) -> Optional[str]:
        """å°‡å ±å‘Šå„²å­˜åˆ°æœ¬åœ° md æª”æ¡ˆ"""
        try:
            # ç”Ÿæˆæª”æ¡ˆåç¨±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = generate_report_filename(
                case_id=report.case_id,
                report_type=report.report_type.value,
                timestamp=timestamp
            )
            
            # æ§‹å»ºå®Œæ•´çš„å ±å‘Šå…§å®¹ï¼ˆåŒ…å« metadataï¼‰
            full_report_content = self._format_report_for_file(report)
            
            # å„²å­˜åˆ°æª”æ¡ˆ
            file_path = save_report_to_file(
                report_content=full_report_content,
                filename=filename,
                directory_path=self.settings.report_history_dir
            )
            
            if file_path:
                print(f"å ±å‘Šå·²å„²å­˜è‡³: {file_path}")
                return str(file_path)
            else:
                print("å ±å‘Šå„²å­˜å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"å„²å­˜å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def _format_report_for_file(self, report: Report) -> str:
        """æ ¼å¼åŒ–å ±å‘Šå…§å®¹ç”¨æ–¼æª”æ¡ˆå„²å­˜"""
        # å ±å‘Šæ¨™é¡Œ
        report_title = "å³æ™‚å›žé¥‹å ±å‘Š" if report.report_type == ReportType.FEEDBACK else "è©³ç´°åˆ†æžå ±å‘Š"
        
        # åŸºæœ¬è³‡è¨Š
        metadata_section = f"""# {report_title}

## å ±å‘Šè³‡è¨Š
- **æ¡ˆä¾‹ ID**: {report.case_id}
- **å ±å‘Šé¡žåž‹**: {report.report_type.value}
- **ç”Ÿæˆæ™‚é–“**: {report.metadata.get('generated_at', 'N/A')}
- **å•è¨ºè¦†è“‹çŽ‡**: {report.coverage}%
- **å°è©±é•·åº¦**: {report.metadata.get('conversation_length', 'N/A')} æ¢è¨Šæ¯

"""
        
        # å¦‚æžœæœ‰å¼•è¨»ï¼Œæ·»åŠ å¼•è¨»è³‡è¨Š
        citations_section = ""
        if report.citations:
            citations_section = f"""
## å¼•è¨»è³‡è¨Š
- **å¼•è¨»æ•¸é‡**: {len(report.citations)}
- **RAG æŸ¥è©¢**: {', '.join(report.rag_queries) if report.rag_queries else 'N/A'}

"""
        
        # å ±å‘Šå…§å®¹
        content_section = f"""
## å ±å‘Šå…§å®¹

{report.content}
"""
        
        # å¦‚æžœæœ‰å¼•è¨»ï¼Œæ·»åŠ è©³ç´°å¼•è¨»
        detailed_citations = ""
        if report.citations:
            detailed_citations = f"""

## è©³ç´°å¼•è¨»

"""
            for i, citation in enumerate(report.citations, 1):
                score_info = ""
                if hasattr(citation, 'score') and citation.score is not None:
                    score_info = f"- **ç›¸é—œæ€§åˆ†æ•¸**: {citation.score:.3f}\n"
                
                detailed_citations += f"""### å¼•è¨» {citation.id}
- **æŸ¥è©¢**: {citation.query}
- **ä¾†æº**: {citation.source}
{score_info}- **å…§å®¹**: 
```
{citation.content}
```

---
"""
        
        # çµ„åˆå®Œæ•´å…§å®¹
        full_content = (
            metadata_section +
            citations_section +
            content_section +
            detailed_citations +
            f"""

---
*æ­¤å ±å‘Šç”± ClinicSim-AI ç³»çµ±è‡ªå‹•ç”Ÿæˆæ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        )
        
        return full_content
    
    def _generate_enhanced_analysis(self, conversation: Conversation, case: Case, scoring_result) -> str:
        """ç”Ÿæˆå¢žå¼·åˆ†æžå ±å‘Šï¼ˆåŒ…å«çµæ§‹åŒ–è©•åˆ†ï¼‰"""
        # åŸºæœ¬è¦†è“‹çŽ‡åˆ†æžï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        checklist = case.get_feedback_checklist()
        conversation_text = conversation.get_conversation_text().lower()
        
        report_items = []
        covered_count = 0
        partial_count = 0
        
        for item in checklist:
            keywords = item.get('keywords', [])
            matched_keywords = [kw for kw in keywords if kw.lower() in conversation_text]
            
            if len(matched_keywords) >= 2:
                report_items.append(f"- âœ… {item['point']}ï¼šå­¸ç”Ÿé€éŽæå•ã€Œ{matched_keywords[0]}ã€ç­‰æˆåŠŸå•è¨º")
                covered_count += 1
            elif len(matched_keywords) == 1:
                report_items.append(f"- âš ï¸ {item['point']}ï¼šå­¸ç”Ÿæœ‰ç›¸é—œæå•ã€Œ{matched_keywords[0]}ã€ï¼Œä½†å¯æ›´æ·±å…¥")
                partial_count += 1
            else:
                report_items.append(f"- âŒ {item['point']}ï¼šå­¸ç”Ÿæœªè©¢å•æ­¤é …ç›®")
        
        # çµæ§‹åŒ–è©•åˆ†åˆ†æž
        scoring_analysis = self._format_scoring_analysis(scoring_result)
        
        coverage_percentage = conversation.coverage
        
        return f"""### è¨ºå¾Œåˆ†æžå ±å‘Š

**ç¸½é«”è©•åˆ†ï¼š{scoring_result.percentage:.1f}% ({scoring_result.grade})**
**å•è¨ºè¦†è“‹çŽ‡ï¼š{coverage_percentage}% ({covered_count + partial_count}/{len(checklist)})**

{scoring_analysis}

**è©³ç´°è©•ä¼°ï¼š**
{chr(10).join(report_items)}

### ç¸½çµèˆ‡å»ºè­°

**å„ªé»žï¼š**
- ç¸½é«”è©•åˆ†é” {scoring_result.percentage:.1f}%ï¼Œç­‰ç´šï¼š{scoring_result.grade}
- å•è¨ºè¦†è“‹çŽ‡é” {coverage_percentage}%ï¼Œå…±è¦†è“‹ {covered_count + partial_count} å€‹é …ç›®
- å­¸ç”Ÿå±•ç¾äº†åŸºæœ¬çš„å•è¨ºæŠ€å·§

**æ”¹é€²å»ºè­°ï¼š**
1. **ç³»çµ±æ€§å•è¨º**ï¼šå»ºè­°æŒ‰ç…§ OPQRST çµæ§‹é€²è¡Œå•è¨º
2. **æ·±å…¥æŽ¢ç´¢**ï¼šå°æ–¼å·²è§¸åŠçš„ä¸»é¡Œï¼Œå¯ä»¥é€²ä¸€æ­¥æ·±å…¥è©¢å•
3. **é—œéµæ±ºç­–**ï¼šåŠ å¼·è‡¨åºŠæ±ºç­–èƒ½åŠ›ï¼ŒåŠæ™‚æå‡ºé—œéµæª¢æŸ¥
4. **å®Œæ•´æ€§**ï¼šæ³¨æ„å•è¨ºçš„å…¨é¢æ€§ï¼Œé¿å…éºæ¼é‡è¦é …ç›®

**å…·é«”å»ºè­°ï¼š**
- å¤šç·´ç¿’æ¨™æº–åŒ–å•è¨ºæµç¨‹
- åŠ å¼·å°é—œéµç—‡ç‹€çš„è­˜åˆ¥èƒ½åŠ›
- æå‡è‡¨åºŠæ±ºç­–çš„æ™‚æ•ˆæ€§

*è¨»ï¼šæ­¤ç‚ºå³æ™‚åˆ†æžå ±å‘Šï¼Œè©³ç´°å ±å‘Šè«‹é»žæ“Šã€Œç”Ÿæˆå®Œæ•´å ±å‘Šã€æŒ‰éˆ•ã€‚*"""
    
    def _format_scoring_analysis(self, scoring_result) -> str:
        """æ ¼å¼åŒ–è©•åˆ†åˆ†æž"""
        analysis_parts = []
        
        # å„é¡žåˆ¥è©•åˆ†
        for section in scoring_result.section_scores:
            section_percentage = (section.achieved_score / section.max_score * 100) if section.max_score > 0 else 0
            analysis_parts.append(f"**{section.title}**: {section_percentage:.1f}% ({section.achieved_score:.1f}/{section.max_score})")
            
            # é¡¯ç¤ºé—œéµé …ç›®
            key_criteria = [c for c in section.criteria_scores if c.achieved_score > 0]
            if key_criteria:
                analysis_parts.append(f"  - å®Œæˆé …ç›®: {', '.join([c.description for c in key_criteria[:3]])}")
            
            # é¡¯ç¤ºæ‡²ç½°é …ç›®
            penalties = [p for p in section.penalties if p.achieved_score > 0]
            if penalties:
                analysis_parts.append(f"  - æ‰£åˆ†é …ç›®: {', '.join([p.description for p in penalties])}")
        
        return "\n".join(analysis_parts)
